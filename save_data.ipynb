{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cerebralcortex/kessel_jupyter_virtualenv/cc33/lib64/python3.6/site-packages/cerebralcortex/core/data_manager/raw/data.py:67: DeprecationWarning: pyarrow.hdfs.connect is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  self.fs = pa.hdfs.connect(self.hdfs_ip, self.hdfs_port)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from pyspark.sql.types import StructField, StructType, DoubleType,MapType, StringType,ArrayType, FloatType, TimestampType, IntegerType\n",
    "from cerebralcortex.core.datatypes import DataStream\n",
    "from cerebralcortex.core.metadata_manager.stream.metadata import Metadata, DataDescriptor, \\\n",
    "ModuleMetadata\n",
    "from scipy import signal\n",
    "from scipy.interpolate import interp1d\n",
    "from cerebralcortex import Kernel\n",
    "from scipy.stats import skew,kurtosis,mode\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "CC = Kernel(\"/home/jupyter/cc3_conf/\", study_name='mperf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_saving(data,\n",
    "                        data_acl,\n",
    "                        stream_name = 'org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity',\n",
    "                        acl_stream_name = 'org.md2k.feature.motionsensehrv.decoded.rightwrist.all',\n",
    "                        activities = ['Walking'],\n",
    "                        window_size = 10,\n",
    "                        base_window_size  = 10,\n",
    "                        prediction_name = 'prediction',\n",
    "                        minutes = 1500):\n",
    "    data = data._data\n",
    "    data = data.select('localtime','timestamp','day',prediction_name,'user','version','start', 'end','std')\n",
    "    \n",
    "#     groupbycols = ['user','version','day',F.window('timestamp',windowDuration=str(window_size)+' seconds', startTime='0 seconds')]\n",
    "#     data_windowed = data.groupBy(groupbycols).agg(F.collect_list('prediction')).withColumnRenamed('collect_list(prediction)','prediction')\n",
    "#     data_windowed = data_windowed.filter(F.size(F.col('prediction'))==window_size//base_window_size)\n",
    "#     def get_most_frequent(a):\n",
    "#         return Counter(a).most_common()[0][0]\n",
    "#     qfunction = F.udf(get_most_frequent,StringType())\n",
    "#     data_windowed = data_windowed.withColumn('prediction',qfunction(data_windowed['prediction']))\n",
    "#     data_windowed = data.filter(F.col(prediction_name).isin(activities))\n",
    "    \n",
    "    if activities[0] not in ['std']:\n",
    "        data_windowed  = data.filter(F.col(prediction_name).isin(activities))\n",
    "        data_windowed = data_windowed.withColumn('time',F.col('timestamp').cast('double'))\n",
    "    else:\n",
    "        data_windowed  = data.filter(F.col('std')>=.21)\n",
    "        data_windowed = data_windowed.withColumn('time',F.col('timestamp').cast('double'))\n",
    "    \n",
    "    n = int(minutes*60/base_window_size)\n",
    "    schema = data_windowed.schema\n",
    "    @pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "    def get_user_data(df):\n",
    "        df = df.sort_values('time').reset_index(drop=True)\n",
    "        df = df[:n]\n",
    "        return df\n",
    "    \n",
    "#     data_windowed = data_windowed.groupBy('user').apply(get_user_data).drop('time')\n",
    "    data_windowed = data_windowed.select('localtime','timestamp','day',prediction_name,'user','version',F.struct('start', 'end').alias('window'))\n",
    "    \n",
    "    \n",
    "    if data_windowed.count()<30*60/base_window_size:\n",
    "        return pd.DataFrame([],columns=list('abcdefgh'))\n",
    "#     data_windowed.printSchema()\n",
    "#     print(data_windowed.count())\n",
    "    \n",
    "    data_acl = data_acl.select('localtime','timestamp','aclx','acly','aclz','user','version')\n",
    "    data_acl = data_acl.withColumn('time',F.col('timestamp').cast('double'))\n",
    "    data_acl = data_acl.withColumn('data',F.array('time','aclx','acly','aclz')).drop('time','aclx','acly','aclz')\n",
    "    groupbycols = ['user','version',F.window('timestamp',windowDuration=str(window_size)+' seconds', startTime='0 seconds')]\n",
    "    data_acl_windowed = data_acl.groupBy(groupbycols).agg(F.collect_list('data')).withColumnRenamed('collect_list(data)','data')\n",
    "#     data_acl_windowed.printSchema()\n",
    "#     data_windowed.printSchema()\n",
    "    data_joined = data_windowed.join(data_acl_windowed.drop('version'),on=['user','window'],how='inner')\n",
    "#     data_joined.printSchema()\n",
    "    \n",
    "    def interpolate_acl(a,window_size=20,fs_now=25,fs_new=25):\n",
    "        x_now = np.linspace(0,window_size,a.shape[0])\n",
    "        f = interp1d(x_now,a,axis=0,fill_value='extrapolate')\n",
    "        x_new = np.linspace(0,window_size,window_size*fs_new)\n",
    "        return f(x_new)\n",
    "    \n",
    "    schema = StructType([\n",
    "        StructField(\"version\", IntegerType()),\n",
    "        StructField(\"user\", StringType()),\n",
    "        StructField(\"localtime\", TimestampType()),\n",
    "        StructField(\"timestamp\", TimestampType()),\n",
    "        StructField(\"start\", TimestampType()),\n",
    "        StructField(\"end\", TimestampType()),\n",
    "        StructField(\"data\", ArrayType(DoubleType())),\n",
    "        StructField(\"day\", StringType()),\n",
    "        StructField(\"prediction\", StringType())\n",
    "    ])\n",
    "\n",
    "    @pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "    def interpolate_data(df):\n",
    "        df['data'] = df['data'].apply(lambda b:np.array([np.array(a) for a in b]).reshape(len(b),4))\n",
    "        df['data'] = df['data'].apply(lambda a:a[a[:,0].argsort()])\n",
    "        df['data'] = df['data'].apply(lambda a:a[:,1:].reshape(a.shape[0],3))\n",
    "        df['data'] = df['data'].apply(lambda a:interpolate_acl(a).reshape(-1))\n",
    "        return df\n",
    "    data_joined = data_joined.withColumn('start',F.col('window').start)\n",
    "    data_joined = data_joined.withColumn('end',F.col('window').end).drop('window')\n",
    "    data_joined = data_joined.groupBy(['user','version','day']).apply(interpolate_data)\n",
    "#     return data_joined.toPandas()\n",
    "    schema = data_joined.schema\n",
    "    stream_metadata = Metadata()\n",
    "    stream_name  = stream_name+'.'+str(window_size)+'.secs.'+str(activities[0]).lower()\n",
    "    print(stream_name)\n",
    "    stream_metadata.set_name(stream_name).set_description(\"ACL data saving for REID model, window size = \"+str(window_size)+' secs')\n",
    "    for field in schema.fields:\n",
    "        stream_metadata.add_dataDescriptor(\n",
    "            DataDescriptor().set_name(str(field.name)).set_type(str(field.dataType))\n",
    "        )\n",
    "    stream_metadata.add_module(\n",
    "        ModuleMetadata().set_name(\"ACL data saving for REID model, window size = \"+str(window_size)+' secs'+str(activities[0]).lower()) \\\n",
    "        .set_attribute(\"url\", \"https://md2k.org\").set_author(\n",
    "            \"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "    ds = DataStream(data=data_joined,metadata=stream_metadata)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cerebralcortex/kessel_jupyter_virtualenv/cc33/lib64/python3.6/site-packages/pyspark/sql/pandas/group_ops.py:76: UserWarning: It is preferred to use 'applyInPandas' over this API. This API will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  \"more details.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity.all.three.20.secs.std\n"
     ]
    }
   ],
   "source": [
    "base_window_size = 20\n",
    "import pickle\n",
    "import os\n",
    "stream_name = 'org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity.all.three'\n",
    "# activities = ['Driving','Sitting','Stairs','Walking']\n",
    "activities =  ['Stationery','Stairs','Exercise','Walking','Sports']\n",
    "activities = ['std']\n",
    "window_size = 20\n",
    "acl_stream_name = 'org.md2k.feature.motionsensehrv.decoded.rightwrist.all'\n",
    "# user_id1 = '3ca3dbf5-2390-409e-bd2c-c9f23a255e75'\n",
    "# users = pickle.load(open('./data/users.p','rb'))\n",
    "\n",
    "directory = './data/'\n",
    "\n",
    "\n",
    "\n",
    "for activity in activities[::-1]:\n",
    "    activity1 = activity\n",
    "#     if not os.path.isdir(directory+str(base_window_size)+'/'+activity1):\n",
    "#         os.makedirs(directory+str(base_window_size)+'/'+activity1)\n",
    "#     for user_id in users[:1]:\n",
    "#     user_id = users[0]\n",
    "    data = CC.get_stream(stream_name)\n",
    "    data_acl = CC.get_stream(acl_stream_name)\n",
    "    df = get_data_for_saving(data,\n",
    "                            data_acl,\n",
    "                            stream_name = stream_name,\n",
    "                            acl_stream_name = acl_stream_name,\n",
    "                            activities = [activity],\n",
    "                            window_size = window_size,\n",
    "                            base_window_size  = base_window_size)\n",
    "    CC.save_stream(df,overwrite=True)\n",
    "#     print(df.shape)\n",
    "        \n",
    "#         print(user_id)\n",
    "#         if df.shape[0]/6 < 30:\n",
    "#             continue\n",
    "#         pickle.dump(df,open(directory+str(base_window_size)+'/'+activity1+'/'+user_id+'.p','wb'))\n",
    "#         print(user_id,df.shape,activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('./data/10/Sitting_test/') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['data'])/6\n",
    "org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity.10.secs.driving\n",
    "org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity.10.secs.driving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CC.get_stream(stream_name+'.'+str(window_size)+'.secs')\n",
    "df = data._data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(df,open('./data/right_wrist/'+user_id+'.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.drop('data').show(1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CC.get_stream('org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity.10.secs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filepath = './data/walking_10/right_wrist/'\n",
    "stream_name = 'org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity.10.secs'\n",
    "users = pickle.load(open('./data/users.p','rb'))\n",
    "for i,user in enumerate(users):\n",
    "    df = CC.get_stream(stream_name,user_id=user)\n",
    "    data  = df.toPandas()\n",
    "    pickle.dump(data,open(filepath+user,'wb'))\n",
    "    print(i,end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxmean_score = pd.read_json('maxmean_10.json')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size':15})\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(maxmean_score,annot=True,fmt='.2f',cmap='Reds',linewidth=1,linecolor='black')\n",
    "plt.title('Max Mean Boosting')\n",
    "plt.xlabel('Train data per user, minutes')\n",
    "plt.ylabel('Test data length, minutes')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./images/maxmean_boosting.png',dps=1e6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxmean_score = pd.read_json('majority_10.json')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size':15})\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(maxmean_score,annot=True,fmt='.2f',cmap='Reds',linewidth=1,linecolor='black')\n",
    "plt.title('Majority Boosting')\n",
    "plt.xlabel('Train data per user, minutes')\n",
    "plt.ylabel('Test data length, minutes')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./images/majority_boosting.png',dps=1e6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0]['data']\n",
    "users\n",
    "import shutil\n",
    "import pickle\n",
    "import os\n",
    "hours = []\n",
    "for f in os.listdir('./data/right_wrist/'):\n",
    "    data = pickle.load(open('./data/right_wrist/'+f,'rb'))\n",
    "    hours.append(data.shape[0]*20/3600)\n",
    "data.shape[0]*20/3600\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "Counter(np.floor(hours))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "High Performance CC3.3",
   "language": "python",
   "name": "cc33_high_performance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
