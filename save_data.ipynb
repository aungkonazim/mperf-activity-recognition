{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from pyspark.sql.types import StructField, StructType, DoubleType,MapType, StringType,ArrayType, FloatType, TimestampType, IntegerType\n",
    "from cerebralcortex.core.datatypes import DataStream\n",
    "from cerebralcortex.core.metadata_manager.stream.metadata import Metadata, DataDescriptor, \\\n",
    "ModuleMetadata\n",
    "from scipy import signal\n",
    "from scipy.interpolate import interp1d\n",
    "from cerebralcortex import Kernel\n",
    "from scipy.stats import skew,kurtosis,mode\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "CC = Kernel(\"/home/jupyter/cc3_conf/\", study_name='mperf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_saving(data,\n",
    "                        data_acl,\n",
    "                        stream_name = 'org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity',\n",
    "                        acl_stream_name = 'org.md2k.feature.motionsensehrv.decoded.rightwrist.all',\n",
    "                        activities = ['Walking'],\n",
    "                        window_size = 10,\n",
    "                        base_window_size  = 10,\n",
    "                        prediction_name = 'prediction',\n",
    "                        minutes = 1000):\n",
    "    data = data._data\n",
    "    data = data.select('localtime','timestamp','day',prediction_name,'user','version','start', 'end')\n",
    "    data  = data.filter(F.col(prediction_name).isin(activities))\n",
    "    \n",
    "#     groupbycols = ['user','version','day',F.window('timestamp',windowDuration=str(window_size)+' seconds', startTime='0 seconds')]\n",
    "#     data_windowed = data.groupBy(groupbycols).agg(F.collect_list('prediction')).withColumnRenamed('collect_list(prediction)','prediction')\n",
    "#     data_windowed = data_windowed.filter(F.size(F.col('prediction'))==window_size//base_window_size)\n",
    "#     def get_most_frequent(a):\n",
    "#         return Counter(a).most_common()[0][0]\n",
    "#     qfunction = F.udf(get_most_frequent,StringType())\n",
    "#     data_windowed = data_windowed.withColumn('prediction',qfunction(data_windowed['prediction']))\n",
    "    data_windowed = data.filter(F.col(prediction_name).isin(activities))\n",
    "    data_windowed = data_windowed.withColumn('time',F.col('timestamp').cast('double'))\n",
    "    n = int(minutes*60/base_window_size)\n",
    "    schema = data_windowed.schema\n",
    "    @pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "    def get_user_data(df):\n",
    "        df = df.sort_values('time').reset_index(drop=True)\n",
    "        df = df[:n]\n",
    "        return df\n",
    "    \n",
    "    data_windowed = data_windowed.groupBy('user').apply(get_user_data).drop('time')\n",
    "    data_windowed = data_windowed.select('localtime','timestamp','day',prediction_name,'user','version',F.struct('start', 'end').alias('window'))\n",
    "    \n",
    "    \n",
    "    if data_windowed.count()<30*6:\n",
    "        return pd.DataFrame([],columns=list('abcdefgh'))\n",
    "#     data_windowed.printSchema()\n",
    "#     print(data_windowed.count())\n",
    "    data_acl = data_acl.select('localtime','timestamp','aclx','acly','aclz','user','version')\n",
    "    data_acl = data_acl.withColumn('time',F.col('timestamp').cast('double'))\n",
    "    data_acl = data_acl.withColumn('data',F.array('time','aclx','acly','aclz')).drop('time','aclx','acly','aclz')\n",
    "    groupbycols = ['user','version',F.window('timestamp',windowDuration=str(window_size)+' seconds', startTime='0 seconds')]\n",
    "    data_acl_windowed = data_acl.groupBy(groupbycols).agg(F.collect_list('data')).withColumnRenamed('collect_list(data)','data')\n",
    "    data_joined = data_windowed.join(data_acl_windowed.drop('version'),on=['user','window'],how='inner')\n",
    "    return data_joined.toPandas()\n",
    "#     print(data_joined.count())\n",
    "#     data_joined.printSchema()\n",
    "#     def reshape_data(a):\n",
    "# #         a = np.array([np.array(b) for b in a])\n",
    "# #         a = a[a[:,0].argsort()]\n",
    "# #         return list(a.reshape(-1))\n",
    "#         return [1,2,3,4]\n",
    "#     qfunction = F.udf(reshape_data,ArrayType(DoubleType()))\n",
    "#     data_joined_final = data_joined.withColumn('data',qfunction(data_joined['data']))\n",
    "\n",
    "#     schema = data_joined.schema\n",
    "#     stream_metadata = Metadata()\n",
    "#     print(stream_name+'.'+str(window_size)+'.secs.'+str(activities[0]).lower())\n",
    "#     stream_metadata.set_name(stream_name+'.'+str(window_size)+'.secs.'+str(activities[0]).lower()).set_description(\"ACL data saving for REID model, window size = \"+str(window_size)+' secs')\n",
    "#     for field in schema.fields:\n",
    "#         stream_metadata.add_dataDescriptor(\n",
    "#             DataDescriptor().set_name(str(field.name)).set_type(str(field.dataType))\n",
    "#         )\n",
    "#     stream_metadata.add_module(\n",
    "#         ModuleMetadata().set_name(\"ACL data saving for REID model, window size = \"+str(window_size)+' secs'+str(activities[0]).lower()) \\\n",
    "#         .set_attribute(\"url\", \"https://md2k.org\").set_author(\n",
    "#             \"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "#     ds = DataStream(data=data_joined,metadata=stream_metadata)\n",
    "#     return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_window_size = 10\n",
    "import pickle\n",
    "import os\n",
    "stream_name = 'org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity'\n",
    "activities = ['Driving','Sitting','Stairs','Walking']\n",
    "window_size = 10\n",
    "acl_stream_name = 'org.md2k.feature.motionsensehrv.decoded.rightwrist.all'\n",
    "user_id1 = '3ca3dbf5-2390-409e-bd2c-c9f23a255e75'\n",
    "users = pickle.load(open('./data/users.p','rb'))\n",
    "\n",
    "directory = './data/'\n",
    "if not os.path.isdir(directory+str(base_window_size)):\n",
    "    os.makedirs(directory+str(base_window_size))\n",
    "\n",
    "for activity in activities:\n",
    "    if not os.path.isdir(directory+str(base_window_size)+'/'+activity):\n",
    "        os.makedirs(directory+str(base_window_size)+'/'+activity)\n",
    "    for user_id in users:\n",
    "        data = CC.get_stream(stream_name,user_id=user_id)\n",
    "        data_acl = CC.get_stream(acl_stream_name,user_id=user_id)\n",
    "        df = get_data_for_saving(data,\n",
    "                                data_acl,\n",
    "                                stream_name = stream_name,\n",
    "                                acl_stream_name = acl_stream_name,\n",
    "                                activities = [activity],\n",
    "                                window_size = window_size,\n",
    "                                base_window_size  = base_window_size)\n",
    "        print(user_id)\n",
    "        if df.shape[0]/6 < 30:\n",
    "            continue\n",
    "        pickle.dump(df,open(directory+str(base_window_size)+'/'+activity+'/'+user_id+'.p','wb'))\n",
    "        print(user_id,df.shape,activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['data'])/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity.10.secs.driving\n",
    "org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity.10.secs.driving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CC.get_stream(stream_name+'.'+str(window_size)+'.secs')\n",
    "df = data._data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(df,open('./data/right_wrist/'+user_id+'.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.drop('data').show(1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CC.get_stream('org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity.10.secs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filepath = './data/walking_10/right_wrist/'\n",
    "stream_name = 'org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity.10.secs'\n",
    "users = pickle.load(open('./data/users.p','rb'))\n",
    "for i,user in enumerate(users):\n",
    "    df = CC.get_stream(stream_name,user_id=user)\n",
    "    data  = df.toPandas()\n",
    "    pickle.dump(data,open(filepath+user,'wb'))\n",
    "    print(i,end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxmean_score = pd.read_json('maxmean_10.json')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size':15})\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(maxmean_score,annot=True,fmt='.2f',cmap='Reds',linewidth=1,linecolor='black')\n",
    "plt.title('Max Mean Boosting')\n",
    "plt.xlabel('Train data per user, minutes')\n",
    "plt.ylabel('Test data length, minutes')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./images/maxmean_boosting.png',dps=1e6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxmean_score = pd.read_json('majority_10.json')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size':15})\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(maxmean_score,annot=True,fmt='.2f',cmap='Reds',linewidth=1,linecolor='black')\n",
    "plt.title('Majority Boosting')\n",
    "plt.xlabel('Train data per user, minutes')\n",
    "plt.ylabel('Test data length, minutes')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./images/majority_boosting.png',dps=1e6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0]['data']\n",
    "\n",
    "users\n",
    "\n",
    "import shutil\n",
    "\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "hours = []\n",
    "for f in os.listdir('./data/right_wrist/'):\n",
    "    data = pickle.load(open('./data/right_wrist/'+f,'rb'))\n",
    "    hours.append(data.shape[0]*20/3600)\n",
    "\n",
    "data.shape[0]*20/3600\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "Counter(np.floor(hours))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CC3.3",
   "language": "python",
   "name": "cc33"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
