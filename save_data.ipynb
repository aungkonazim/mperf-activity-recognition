{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cerebralcortex/kessel_jupyter_virtualenv/cc33/lib64/python3.6/site-packages/cerebralcortex/core/data_manager/raw/data.py:67: DeprecationWarning: pyarrow.hdfs.connect is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  self.fs = pa.hdfs.connect(self.hdfs_ip, self.hdfs_port)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from pyspark.sql.types import StructField, StructType, DoubleType,MapType, StringType,ArrayType, FloatType, TimestampType, IntegerType\n",
    "from cerebralcortex.core.datatypes import DataStream\n",
    "from cerebralcortex.core.metadata_manager.stream.metadata import Metadata, DataDescriptor, \\\n",
    "ModuleMetadata\n",
    "from scipy import signal\n",
    "from scipy.interpolate import interp1d\n",
    "from cerebralcortex import Kernel\n",
    "from scipy.stats import skew,kurtosis,mode\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "CC = Kernel(\"/home/jupyter/cc3_conf/\", study_name='moral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_saving_moral(data,\n",
    "                        data_acl,\n",
    "                        stream_name = 'org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity',\n",
    "                        acl_stream_name = 'org.md2k.feature.motionsensehrv.decoded.rightwrist.all',\n",
    "                        activities = ['Walking'],\n",
    "                        window_size = 20,\n",
    "                        base_window_size  = 20,\n",
    "                        prediction_name = 'prediction'):\n",
    "    data = data._data\n",
    "    data = data.select('localtime','timestamp','day',prediction_name,'user','version','start', 'end','std')\n",
    "    data_windowed  = data.filter(F.col(prediction_name).isin(activities))\n",
    "    data_windowed = data_windowed.withColumn('time',F.col('timestamp').cast('double'))\n",
    "    data_windowed = data_windowed.select('localtime','timestamp','day',prediction_name,'user','version',F.struct('start', 'end').alias('window'))\n",
    "    if data_windowed.count()<30*60/base_window_size:\n",
    "        return pd.DataFrame([],columns=list('abcdefgh'))\n",
    "    \n",
    "    data_acl = data_acl.select('localtime','timestamp','x','y','z','user','version')\n",
    "    data_acl = data_acl.withColumn('time',F.col('timestamp').cast('double'))\n",
    "    data_acl = data_acl.withColumn('data',F.array('time','x','y','z')).drop('time','x','y','z')\n",
    "    groupbycols = ['user','version',F.window('timestamp',windowDuration=str(window_size)+' seconds', \n",
    "                                             startTime='0 seconds',slideDuration=str(window_size//2)+' seconds')]\n",
    "    data_acl_windowed = data_acl.groupBy(groupbycols).agg(F.collect_list('data')).withColumnRenamed('collect_list(data)','data')\n",
    "    data_joined = data_windowed.join(data_acl_windowed.drop('version'),on=['user','window'],how='inner')\n",
    "\n",
    "    def interpolate_acl(a,window_size=20,fs_now=25,fs_new=25):\n",
    "        x_now = np.linspace(0,window_size,a.shape[0])\n",
    "        f = interp1d(x_now,a,axis=0,fill_value='extrapolate')\n",
    "        x_new = np.linspace(0,window_size,window_size*fs_new)\n",
    "        return f(x_new)\n",
    "    \n",
    "    schema = StructType([\n",
    "        StructField(\"version\", IntegerType()),\n",
    "        StructField(\"user\", StringType()),\n",
    "        StructField(\"localtime\", TimestampType()),\n",
    "        StructField(\"timestamp\", TimestampType()),\n",
    "        StructField(\"start\", TimestampType()),\n",
    "        StructField(\"end\", TimestampType()),\n",
    "        StructField(\"data\", ArrayType(DoubleType())),\n",
    "        StructField(\"day\", StringType()),\n",
    "        StructField(\"prediction\", StringType())\n",
    "    ])\n",
    "\n",
    "    @pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "    def interpolate_data(df):\n",
    "        df['data'] = df['data'].apply(lambda b:np.array([np.array(a) for a in b]).reshape(len(b),4))\n",
    "        df['data'] = df['data'].apply(lambda a:a[a[:,0].argsort()])\n",
    "        df['data'] = df['data'].apply(lambda a:a[:,1:].reshape(a.shape[0],3))\n",
    "        df['data'] = df['data'].apply(lambda a:interpolate_acl(a).reshape(-1))\n",
    "        return df\n",
    "    data_joined = data_joined.withColumn('start',F.col('window').start)\n",
    "    data_joined = data_joined.withColumn('end',F.col('window').end).drop('window')\n",
    "    data_joined = data_joined.groupBy(['user','version','day']).apply(interpolate_data)\n",
    "    schema = data_joined.schema\n",
    "    stream_metadata = Metadata()\n",
    "    stream_name  = stream_name+'.'+str(window_size)+'.secs.'+str(activities[0]).lower()\n",
    "    print(stream_name)\n",
    "    stream_metadata.set_name(stream_name).set_description(\"ACL data saving for REID model, window size = \"+str(window_size)+' secs')\n",
    "    for field in schema.fields:\n",
    "        stream_metadata.add_dataDescriptor(\n",
    "            DataDescriptor().set_name(str(field.name)).set_type(str(field.dataType))\n",
    "        )\n",
    "    stream_metadata.add_module(\n",
    "        ModuleMetadata().set_name(\"ACL data saving for REID model, window size = \"+str(window_size)+' secs'+str(activities[0]).lower()) \\\n",
    "        .set_attribute(\"url\", \"https://md2k.org\").set_author(\n",
    "            \"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "    ds = DataStream(data=data_joined,metadata=stream_metadata)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cerebralcortex/kessel_jupyter_virtualenv/cc33/lib64/python3.6/site-packages/pyspark/sql/pandas/group_ops.py:76: UserWarning: It is preferred to use 'applyInPandas' over this API. This API will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  \"more details.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accelerometer--org.md2k.motionsense--motion_sense--right_wrist.activity.all.three.20.secs.sports\n",
      "accelerometer--org.md2k.motionsense--motion_sense--right_wrist.activity.all.three.20.secs.walking\n",
      "accelerometer--org.md2k.motionsense--motion_sense--right_wrist.activity.all.three.20.secs.exercise\n",
      "accelerometer--org.md2k.motionsense--motion_sense--right_wrist.activity.all.three.20.secs.stairs\n",
      "accelerometer--org.md2k.motionsense--motion_sense--right_wrist.activity.all.three.20.secs.stationery\n"
     ]
    }
   ],
   "source": [
    "base_window_size = 20\n",
    "import pickle\n",
    "import os\n",
    "stream_name = 'accelerometer--org.md2k.motionsense--motion_sense--right_wrist'+'.activity.all.three'\n",
    "activities =  ['Stationery','Stairs','Exercise','Walking','Sports']\n",
    "window_size = 20\n",
    "acl_stream_name = 'accelerometer--org.md2k.motionsense--motion_sense--right_wrist'\n",
    "for activity in activities[::-1]:\n",
    "    try:\n",
    "        activity1 = activity\n",
    "        data = CC.get_stream(stream_name)\n",
    "        data_acl = CC.get_stream(acl_stream_name)\n",
    "        df = get_data_for_saving_moral(data,\n",
    "                                data_acl,\n",
    "                                stream_name = stream_name,\n",
    "                                acl_stream_name = acl_stream_name,\n",
    "                                activities = [activity],\n",
    "                                window_size = window_size,\n",
    "                                base_window_size  = base_window_size)\n",
    "        CC.save_stream(df,overwrite=True)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CC.get_stream('accelerometer--org.md2k.motionsense--motion_sense--right_wrist.activity.all.three.20.secs.walking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_saving(data,\n",
    "                        data_acl,\n",
    "                        stream_name = 'org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity',\n",
    "                        acl_stream_name = 'org.md2k.feature.motionsensehrv.decoded.rightwrist.all',\n",
    "                        activities = ['Walking'],\n",
    "                        window_size = 20,\n",
    "                        base_window_size  = 20,\n",
    "                        prediction_name = 'prediction',\n",
    "                        minutes = 1500):\n",
    "    data = data._data\n",
    "    data = data.select('localtime','timestamp','day',prediction_name,'user','version','start', 'end','std')\n",
    "    \n",
    "#     groupbycols = ['user','version','day',F.window('timestamp',windowDuration=str(window_size)+' seconds', startTime='0 seconds')]\n",
    "#     data_windowed = data.groupBy(groupbycols).agg(F.collect_list('prediction')).withColumnRenamed('collect_list(prediction)','prediction')\n",
    "#     data_windowed = data_windowed.filter(F.size(F.col('prediction'))==window_size//base_window_size)\n",
    "#     def get_most_frequent(a):\n",
    "#         return Counter(a).most_common()[0][0]\n",
    "#     qfunction = F.udf(get_most_frequent,StringType())\n",
    "#     data_windowed = data_windowed.withColumn('prediction',qfunction(data_windowed['prediction']))\n",
    "#     data_windowed = data.filter(F.col(prediction_name).isin(activities))\n",
    "    \n",
    "    if activities[0][:3] not in ['std']:\n",
    "        data_windowed  = data.filter(F.col(prediction_name).isin(activities))\n",
    "        data_windowed = data_windowed.withColumn('time',F.col('timestamp').cast('double'))\n",
    "    else:\n",
    "        threshold = int(activities[0][3:])/100\n",
    "        print(threshold)\n",
    "        data_windowed  = data.filter(F.col('std')>=threshold)\n",
    "        data_windowed = data_windowed.withColumn('time',F.col('timestamp').cast('double'))\n",
    "    \n",
    "    n = int(minutes*60/base_window_size)\n",
    "    schema = data_windowed.schema\n",
    "    @pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "    def get_user_data(df):\n",
    "        df = df.sort_values('time').reset_index(drop=True)\n",
    "        df = df[:n]\n",
    "        return df\n",
    "    \n",
    "#     data_windowed = data_windowed.groupBy('user').apply(get_user_data).drop('time')\n",
    "    data_windowed = data_windowed.select('localtime','timestamp','day',prediction_name,'user','version',F.struct('start', 'end').alias('window'))\n",
    "    \n",
    "    \n",
    "    if data_windowed.count()<30*60/base_window_size:\n",
    "        return pd.DataFrame([],columns=list('abcdefgh'))\n",
    "#     data_windowed.printSchema()\n",
    "#     print(data_windowed.count())\n",
    "    \n",
    "    data_acl = data_acl.select('localtime','timestamp','aclx','acly','aclz','user','version')\n",
    "    data_acl = data_acl.withColumn('time',F.col('timestamp').cast('double'))\n",
    "    data_acl = data_acl.withColumn('data',F.array('time','aclx','acly','aclz')).drop('time','aclx','acly','aclz')\n",
    "    groupbycols = ['user','version',F.window('timestamp',windowDuration=str(window_size)+' seconds', startTime='0 seconds')]\n",
    "    data_acl_windowed = data_acl.groupBy(groupbycols).agg(F.collect_list('data')).withColumnRenamed('collect_list(data)','data')\n",
    "#     data_acl_windowed.printSchema()\n",
    "#     data_windowed.printSchema()\n",
    "    data_joined = data_windowed.join(data_acl_windowed.drop('version'),on=['user','window'],how='inner')\n",
    "#     data_joined.printSchema()\n",
    "    \n",
    "    def interpolate_acl(a,window_size=20,fs_now=25,fs_new=25):\n",
    "        x_now = np.linspace(0,window_size,a.shape[0])\n",
    "        f = interp1d(x_now,a,axis=0,fill_value='extrapolate')\n",
    "        x_new = np.linspace(0,window_size,window_size*fs_new)\n",
    "        return f(x_new)\n",
    "    \n",
    "    schema = StructType([\n",
    "        StructField(\"version\", IntegerType()),\n",
    "        StructField(\"user\", StringType()),\n",
    "        StructField(\"localtime\", TimestampType()),\n",
    "        StructField(\"timestamp\", TimestampType()),\n",
    "        StructField(\"start\", TimestampType()),\n",
    "        StructField(\"end\", TimestampType()),\n",
    "        StructField(\"data\", ArrayType(DoubleType())),\n",
    "        StructField(\"day\", StringType()),\n",
    "        StructField(\"prediction\", StringType())\n",
    "    ])\n",
    "\n",
    "    @pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "    def interpolate_data(df):\n",
    "        df['data'] = df['data'].apply(lambda b:np.array([np.array(a) for a in b]).reshape(len(b),4))\n",
    "        df['data'] = df['data'].apply(lambda a:a[a[:,0].argsort()])\n",
    "        df['data'] = df['data'].apply(lambda a:a[:,1:].reshape(a.shape[0],3))\n",
    "        df['data'] = df['data'].apply(lambda a:interpolate_acl(a).reshape(-1))\n",
    "        return df\n",
    "    data_joined = data_joined.withColumn('start',F.col('window').start)\n",
    "    data_joined = data_joined.withColumn('end',F.col('window').end).drop('window')\n",
    "    data_joined = data_joined.groupBy(['user','version','day']).apply(interpolate_data)\n",
    "#     return data_joined.toPandas()\n",
    "    schema = data_joined.schema\n",
    "    stream_metadata = Metadata()\n",
    "    stream_name  = stream_name+'.'+str(window_size)+'.secs.'+str(activities[0]).lower()\n",
    "    print(stream_name)\n",
    "    stream_metadata.set_name(stream_name).set_description(\"ACL data saving for REID model, window size = \"+str(window_size)+' secs')\n",
    "    for field in schema.fields:\n",
    "        stream_metadata.add_dataDescriptor(\n",
    "            DataDescriptor().set_name(str(field.name)).set_type(str(field.dataType))\n",
    "        )\n",
    "    stream_metadata.add_module(\n",
    "        ModuleMetadata().set_name(\"ACL data saving for REID model, window size = \"+str(window_size)+' secs'+str(activities[0]).lower()) \\\n",
    "        .set_attribute(\"url\", \"https://md2k.org\").set_author(\n",
    "            \"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "    ds = DataStream(data=data_joined,metadata=stream_metadata)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_window_size = 20\n",
    "import pickle\n",
    "import os\n",
    "stream_name = 'org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity.all.three'\n",
    "# activities = ['Driving','Sitting','Stairs','Walking']\n",
    "activities =  ['Stationery','Stairs','Exercise','Walking','Sports']\n",
    "activities = ['std25','std15','std10','std30']\n",
    "activities = ['std5']\n",
    "window_size = 20\n",
    "acl_stream_name = 'org.md2k.feature.motionsensehrv.decoded.rightwrist.all'\n",
    "# user_id1 = '3ca3dbf5-2390-409e-bd2c-c9f23a255e75'\n",
    "# users = pickle.load(open('./data/users.p','rb'))\n",
    "\n",
    "directory = './data/'\n",
    "\n",
    "\n",
    "\n",
    "for activity in activities[::-1]:\n",
    "    activity1 = activity\n",
    "#     if not os.path.isdir(directory+str(base_window_size)+'/'+activity1):\n",
    "#         os.makedirs(directory+str(base_window_size)+'/'+activity1)\n",
    "#     for user_id in users[:1]:\n",
    "#     user_id = users[0]\n",
    "    data = CC.get_stream(stream_name)\n",
    "    data_acl = CC.get_stream(acl_stream_name)\n",
    "    df = get_data_for_saving(data,\n",
    "                            data_acl,\n",
    "                            stream_name = stream_name,\n",
    "                            acl_stream_name = acl_stream_name,\n",
    "                            activities = [activity],\n",
    "                            window_size = window_size,\n",
    "                            base_window_size  = base_window_size)\n",
    "    CC.save_stream(df,overwrite=True)\n",
    "#     print(df.shape)\n",
    "        \n",
    "#         print(user_id)\n",
    "#         if df.shape[0]/6 < 30:\n",
    "#             continue\n",
    "#         pickle.dump(df,open(directory+str(base_window_size)+'/'+activity1+'/'+user_id+'.p','wb'))\n",
    "#         print(user_id,df.shape,activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CC.get_stream(stream_name+'.'+str(window_size)+'.secs')\n",
    "df = data._data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(df,open('./data/right_wrist/'+user_id+'.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.drop('data').show(1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CC.get_stream('org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity.all.three').drop('magnitude','start','end')\n",
    "schema = StructType([\n",
    "    StructField(\"timestamp\", TimestampType()),\n",
    "    StructField(\"localtime\", TimestampType()),\n",
    "    StructField(\"start\", TimestampType()),\n",
    "    StructField(\"end\", TimestampType()),\n",
    "    StructField(\"version\", IntegerType()),\n",
    "    StructField(\"user\", StringType()),\n",
    "    StructField(\"prediction\", StringType()),\n",
    "    StructField(\"std\", DoubleType()),\n",
    "    StructField(\"day\", StringType())\n",
    "])\n",
    "from scipy.stats import mode\n",
    "import pandas as pd\n",
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "def minutewise_data(key,df):\n",
    "    timestamp = df['timestamp'].values[0]\n",
    "    localtime = df['localtime'].values[0]\n",
    "    version = 1\n",
    "    user = df['user'].values[0]\n",
    "    prediction = mode(df['prediction'].values)[0][0]\n",
    "    day = df['day'].values[0]\n",
    "    std_value = np.mean(df['std'].values)\n",
    "    rows = []\n",
    "    rows.append([timestamp,localtime,version,user,prediction,std_value,day,key[3]['start'],key[3]['end']])\n",
    "    return pd.DataFrame(rows,columns=['timestamp','localtime','version','user','prediction','std','day','start','end'])\n",
    "win = F.window(\"timestamp\", windowDuration='60 seconds',slideDuration='60 seconds',startTime='0 seconds')\n",
    "data_60 = data.groupBy(['user','version','day',win]).apply(minutewise_data)\n",
    "\n",
    "schema = data_60.schema\n",
    "stream_metadata = Metadata()\n",
    "stream_metadata.set_name('org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity.all.three.60.secs').set_description(\"right wrist 60 secs yield\")\n",
    "for field in schema.fields:\n",
    "    stream_metadata.add_dataDescriptor(\n",
    "        DataDescriptor().set_name(str(field.name)).set_type(str(field.dataType))\n",
    "    )\n",
    "stream_metadata.add_module(\n",
    "    ModuleMetadata().set_name(\"right wrist 60 secs yield\") \\\n",
    "    .set_attribute(\"url\", \"https://md2k.org\").set_author(\n",
    "        \"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "stream_metadata.is_valid()\n",
    "ds = DataStream(data=data_60,metadata=stream_metadata)\n",
    "CC.save_stream(ds,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CC.get_stream('org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity.all.three.60.secs')\n",
    "\n",
    "schema = data.schema\n",
    "columns = [a.name for a in schema.fields]\n",
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "def filter_daywise(df):\n",
    "    if df.shape[0]<=120:\n",
    "        return pd.DataFrame([],columns=columns)\n",
    "    return df\n",
    "data_60 = data.groupBy(['user','day']).apply(filter_daywise)\n",
    "\n",
    "schema = data_60.schema\n",
    "stream_metadata = Metadata()\n",
    "stream_metadata.set_name('org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity.all.three.60.secs.filtered').set_description(\"right wrist 60 secs yield\")\n",
    "for field in schema.fields:\n",
    "    stream_metadata.add_dataDescriptor(\n",
    "        DataDescriptor().set_name(str(field.name)).set_type(str(field.dataType))\n",
    "    )\n",
    "stream_metadata.add_module(\n",
    "    ModuleMetadata().set_name(\"right wrist 60 secs yield\") \\\n",
    "    .set_attribute(\"url\", \"https://md2k.org\").set_author(\n",
    "        \"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "stream_metadata.is_valid()\n",
    "ds = DataStream(data=data_60,metadata=stream_metadata)\n",
    "CC.save_stream(ds,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "data = CC.get_stream('org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity.all.three.60.secs.filtered')\n",
    "data.printSchema()\n",
    "schema =  StructType([\n",
    "    StructField(\"timestamp\", TimestampType()),\n",
    "    StructField(\"localtime\", TimestampType()),\n",
    "    StructField(\"version\", IntegerType()),\n",
    "    StructField(\"user\", StringType()),\n",
    "    StructField(\"prediction_count\", ArrayType(DoubleType())),\n",
    "    StructField(\"prediction_percentage\", ArrayType(DoubleType())),\n",
    "    StructField(\"std_count\", ArrayType(DoubleType())),\n",
    "    StructField(\"std_percentage\", ArrayType(DoubleType())),\n",
    "    StructField(\"day\", StringType())\n",
    "])\n",
    "\n",
    "stds = np.arange(.01,.31,.01)\n",
    "activities = ['Stationery','Stairs','Exercise','Walking','Sports']\n",
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "def daywise_count(df):\n",
    "    timestamp = df['timestamp'].values[0]\n",
    "    localtime = df['localtime'].values[0]\n",
    "    version  = 1\n",
    "    user = df['user'].values[0]\n",
    "    day = df['day'].values[0]\n",
    "    activity_counts = Counter(df['prediction'].values)\n",
    "    prediction_count = np.array([0]*len(activities))\n",
    "    for i,activity in enumerate(activities):\n",
    "        if activity in activity_counts:\n",
    "            prediction_count[i] = activity_counts[activity]/60\n",
    "    prediction_percentage = 100*prediction_count/np.sum(prediction_count)\n",
    "    std_count = np.array([0]*len(stds))\n",
    "    for i,std_value in enumerate(stds):\n",
    "        std_count[i] = df[df['std']>=std_value].shape[0]/60\n",
    "    std_percentage = 100*std_count/(df.shape[0]/60)\n",
    "    return pd.DataFrame([[timestamp,localtime,version,user,day,prediction_count,prediction_percentage,std_count,std_percentage]],\n",
    "                       columns = ['timestamp','localtime','version','user','day',\n",
    "                                  'prediction_count','prediction_percentage','std_count',\n",
    "                                 'std_percentage'])\n",
    "    \n",
    "data_60 = data.groupBy(['user','day']).apply(daywise_count)\n",
    "schema = data_60.schema\n",
    "stream_metadata = Metadata()\n",
    "stream_metadata.set_name('org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity.all.three.60.secs.filtered.count.percentage').set_description(\"right wrist daywise yield\")\n",
    "for field in schema.fields:\n",
    "    stream_metadata.add_dataDescriptor(\n",
    "        DataDescriptor().set_name(str(field.name)).set_type(str(field.dataType))\n",
    "    )\n",
    "stream_metadata.add_module(\n",
    "    ModuleMetadata().set_name(\"right wrist daywise yield\") \\\n",
    "    .set_attribute(\"url\", \"https://md2k.org\").set_author(\n",
    "        \"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "stream_metadata.is_valid()\n",
    "ds = DataStream(data=data_60,metadata=stream_metadata)\n",
    "CC.save_stream(ds,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = CC.get_stream('org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity.all.three.60.secs.filtered.count.percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data._data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(data,open('./data/daywise_count_percentage.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data  = pickle.load(open('./data/daywise_count_percentage.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['count'] = data['prediction_count'].apply(lambda a:sum(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('user').sum().mean()*.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['user_day'] = data.apply(lambda a:a['user']+a['day'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['user_day'].unique().shape,19950/353"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stationery'] = data['prediction_percentage'].apply(lambda a:a[0])\n",
    "data['sports'] = data['prediction_percentage'].apply(lambda a:a[-1])\n",
    "data['walking'] = data['prediction_percentage'].apply(lambda a:sum(a[1:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stationery'].mean(),data['sports'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data['prediction_count'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = [sum(b) for b in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [b for b in a if b[0] is not None and b[0]>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([b[0] for b in a if b[0]>2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([b[2] for b in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([b[-1] for b in a if b[-1]>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([b[1]+b[3] for b in a if b[3]>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = np.arange(.01,.31,.01)\n",
    "activities = ['Stationery','Stairs','Exercise','Walking','Sports']\n",
    "column_name='std_count'\n",
    "if column_name.split('_')[0]=='prediction':\n",
    "    x = activities\n",
    "else:\n",
    "    x = stds\n",
    "    x = [np.round(a*100)/100 for a in x]\n",
    "rows = []\n",
    "for i,row in data.iterrows():\n",
    "    for j,value in enumerate(x):\n",
    "        rows.append([value,row[column_name][j],row['user'],row['day']])\n",
    "df = pd.DataFrame(rows,columns=['Activity Type','value','user','day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size':25})\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.barplot(x='Activity Type',y='value',data=df)\n",
    "if column_name.split('_')[1]=='count':\n",
    "    plt.ylabel('Hours per user day')\n",
    "else:\n",
    "    plt.ylabel('Percentage per user day')\n",
    "if column_name.split('_')[0]=='std':\n",
    "    plt.xlabel('Accelerometer Standard Deviation')\n",
    "else:\n",
    "    plt.xlabel('Activity Type')\n",
    "plt.xticks(rotation=60)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./images/'+column_name+'.png',dps=1e6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Activity Type').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filepath = './data/walking_10/right_wrist/'\n",
    "stream_name = 'org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity.10.secs'\n",
    "users = pickle.load(open('./data/users.p','rb'))\n",
    "for i,user in enumerate(users):\n",
    "    df = CC.get_stream(stream_name,user_id=user)\n",
    "    data  = df.toPandas()\n",
    "    pickle.dump(data,open(filepath+user,'wb'))\n",
    "    print(i,end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxmean_score = pd.read_json('maxmean_10.json')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size':15})\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(maxmean_score,annot=True,fmt='.2f',cmap='Reds',linewidth=1,linecolor='black')\n",
    "plt.title('Max Mean Boosting')\n",
    "plt.xlabel('Train data per user, minutes')\n",
    "plt.ylabel('Test data length, minutes')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./images/maxmean_boosting.png',dps=1e6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxmean_score = pd.read_json('majority_10.json')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size':15})\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(maxmean_score,annot=True,fmt='.2f',cmap='Reds',linewidth=1,linecolor='black')\n",
    "plt.title('Majority Boosting')\n",
    "plt.xlabel('Train data per user, minutes')\n",
    "plt.ylabel('Test data length, minutes')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./images/majority_boosting.png',dps=1e6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0]['data']\n",
    "users\n",
    "import shutil\n",
    "import pickle\n",
    "import os\n",
    "hours = []\n",
    "for f in os.listdir('./data/right_wrist/'):\n",
    "    data = pickle.load(open('./data/right_wrist/'+f,'rb'))\n",
    "    hours.append(data.shape[0]*20/3600)\n",
    "data.shape[0]*20/3600\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "Counter(np.floor(hours))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "High Performance CC3.3",
   "language": "python",
   "name": "cc33_high_performance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
