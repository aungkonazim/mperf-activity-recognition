{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cerebralcortex/kessel_jupyter_virtualenv/tensorflow/lib/python3.7/site-packages/pandas-1.2.3-py3.7-linux-x86_64.egg/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Conv1D,BatchNormalization,Dropout,Input,MaxPooling1D,Flatten,Dense,Input,Activation,GRU\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import Parallel,delayed\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,"
     ]
    }
   ],
   "source": [
    "directory = './data/10/Walking/'\n",
    "X,y = [],[]\n",
    "for i,f in enumerate(list(os.listdir(directory))):\n",
    "    if f[0]=='.':\n",
    "        continue\n",
    "    df  = pickle.load(open(directory+f,'rb'))\n",
    "    df['time'] = df['window'].apply(lambda a:a[0])\n",
    "    df['data'] = df['data'].apply(lambda a:np.array([np.array(b) for b in a]))\n",
    "    df['data'] = df['data'].apply(lambda a:a[a[:,0].argsort(),:].reshape(1,-1,4))\n",
    "    df['data'] = df['data'].apply(lambda a:a[:,:,1:])\n",
    "    df = df.sort_values('time').reset_index(drop=True)\n",
    "    user_id = df.user.values[0]\n",
    "    X.append(np.concatenate(list(df['data'].values)))\n",
    "    y.append(user_id)\n",
    "#     X_test.append(np.concatenate(list(df['data'].values)))\n",
    "#     y_train.extend([user_id]*X_train[-1].shape[0])\n",
    "#     y_test.extend([user_id]*X_test[-1].shape[0])\n",
    "    del df\n",
    "    print(i,end=',')\n",
    "pickle.dump([X,y],open('./data/10/walking_all_data1.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump([X,y],open('./data/10/sitting_all_data1.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './data/10/Walking/'\n",
    "data_all = []\n",
    "for f in list(os.listdir(directory)):\n",
    "    if f[0]=='.':\n",
    "        continue\n",
    "    data_all.append(pickle.load(open(directory+f,'rb')))\n",
    "data_all[-1].head()  \n",
    "data  = pd.concat(data_all)\n",
    "del data_all\n",
    "unique_users = data.user.unique()\n",
    "unique_users_dict = {u:i for i,u in enumerate(unique_users)}\n",
    "data['user_id'] = data['user'].apply(lambda a:unique_users_dict[a])\n",
    "data['time'] = data['window'].apply(lambda a:a[0])\n",
    "data['data'] = data['data'].apply(lambda a:np.array([np.array(b) for b in a]))\n",
    "data['data'] = data['data'].apply(lambda a:a[a[:,0].argsort(),:].reshape(1,-1,4))\n",
    "data['data'] = data['data'].apply(lambda a:a[:,:,1:])\n",
    "pickle.dump(data,open('./data/10/walking_all_data.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = pickle.load(open('./data/10/sitting_all_data.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape=(500,3),n_classes=1):\n",
    "    model =  Sequential()\n",
    "    model.add(Conv1D(128,2,input_shape=input_shape,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Conv1D(128,2,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "#     model.add(Conv1D(128,2,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "#     model.add(MaxPooling1D(2))\n",
    "#     model.add(Conv1D(128,2,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "#     model.add(MaxPooling1D(2))\n",
    "    model.add(Activation('tanh'))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(GRU(128,return_sequences=True,activation='tanh'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Dense(n_classes,activation='softmax'))\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),optimizer='adam')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_test_scores(model,x_test,y_test,test_size=None,n_iter=1000,base_window_size=20):\n",
    "    def get_score(user,test_size,n_iter,base_window_size):\n",
    "        df = test_df[test_df.original==user]\n",
    "        score1 = []\n",
    "        score2 = []\n",
    "        test_lengths = []\n",
    "        for t in test_size:\n",
    "            n  = np.int64(t*60/base_window_size)\n",
    "            if n>df.shape[0]:\n",
    "                continue\n",
    "            y_true = [df['original'].values[0]]*n_iter\n",
    "            y_pred_majority = []\n",
    "    #         y_pred_maxmean = []\n",
    "            for i in range(n_iter):\n",
    "                temp_df = df.sample(n,replace=False)\n",
    "                y_pred_majority.append(mode(temp_df['prediction'].values)[0][0])\n",
    "    #             temp_df = np.mean(np.concatenate(list(temp_df['probability'])),axis=0)\n",
    "    #             y_pred_maxmean.append(np.argmax(temp_df))\n",
    "\n",
    "\n",
    "            majority_score = accuracy_score(y_true,y_pred_majority)\n",
    "    #         maxmean_score = accuracy_score(y_true,y_pred_maxmean)\n",
    "            score1.append(majority_score)\n",
    "    #         score2.append(maxmean_score)\n",
    "            test_lengths.append(t)\n",
    "        \n",
    "        df = pd.DataFrame({'majority_score':score1,\n",
    "    #                         'maxmean_score':score2,\n",
    "                            'test_lengths':test_lengths})\n",
    "#         print(df.loc[0])\n",
    "        return df\n",
    "    \n",
    "    y_pred = model.predict(x_test).argmax(axis=1)\n",
    "#     y_pred1 = y_pred.argmax(axis=1)\n",
    "    test_df = pd.DataFrame({'prediction':y_pred,'original':y_test})\n",
    "#                             'probability':list(y_pred)})\n",
    "#     test_df['probability'] = test_df['probability'].apply(lambda a:a.reshape(1,-1)) \n",
    "    if test_size is None:\n",
    "        test_size = np.arange(1,120,1)\n",
    "    del x_test\n",
    "    \n",
    "    result  = Parallel(verbose=2,n_jobs=30)(delayed(get_score)(user,test_size,n_iter,base_window_size) for user in np.unique(test_df.original.values))\n",
    "    test_score = pd.concat(result)\n",
    "    acc_ = accuracy_score(test_df['original'],test_df['prediction'])\n",
    "    \n",
    "    test_score = test_score.append(pd.DataFrame({'majority_score':[acc_],\n",
    "#                                                     'maxmean_score':[acc_],\n",
    "                                                    'test_lengths':[0]}))\n",
    "    test_score = test_score.groupby('test_lengths',as_index=False).mean()\n",
    "    return test_score\n",
    "\n",
    "\n",
    "\n",
    "def get_trained_model(X_train,y_train,n_timesteps,n_channels,window_size,filepath):\n",
    "    n_classes = len(np.unique(y_train))\n",
    "    model =  get_model(input_shape=(n_timesteps,n_channels),n_classes=n_classes)\n",
    "#     model.summary()\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='min',save_weights_only=False)\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=40)\n",
    "    callbacks_list = [es,checkpoint]\n",
    "#     train_x,test_x,train_y,test_y = train_test_split(X_train,y_train,test_size=.2,stratify=y_train)\n",
    "    train_x,val_x,train_y,val_y = train_test_split(X_train,y_train,test_size=.2,stratify=y_train)\n",
    "    history = model.fit(train_x,train_y,validation_data=(val_x,val_y), epochs=200, batch_size=300,verbose=0,\n",
    "          callbacks=callbacks_list,shuffle=True)\n",
    "    model.load_weights(filepath)\n",
    "#     y_pred = model.predict(test_x).argmax(axis=1)\n",
    "\n",
    "#     from sklearn.metrics import classification_report\n",
    "\n",
    "#     print(accuracy_score(test_y,y_pred),window_size)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_training_testing(window_size=10,\n",
    "                         base_window_size=10):\n",
    "    n_train = window_size*60//base_window_size\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    def split_data(df):\n",
    "        filepath = directory+df['user'].values[0]\n",
    "        df  = pickle.load(open(filepath,'rb'))\n",
    "        if df.shape[0]<n_train+30*6:\n",
    "            print(filepath[-2:],end=',')\n",
    "            return \n",
    "        df['time'] = df['window'].apply(lambda a:a[0])\n",
    "        df['data'] = df['data'].apply(lambda a:np.array([np.array(b) for b in a]))\n",
    "        df['data'] = df['data'].apply(lambda a:a[a[:,0].argsort(),:].reshape(1,-1,4))\n",
    "        df['data'] = df['data'].apply(lambda a:a[:,:,1:])\n",
    "        df = df.sort_values('time').reset_index(drop=True)\n",
    "        user_id = df.user.values[0]\n",
    "        X_train.append(np.concatenate(list(df[:n_train]['data'].values)))\n",
    "        X_test.append(np.concatenate(list(df[n_train:]['data'].values)))\n",
    "        y_train.extend([user_id]*X_train[-1].shape[0])\n",
    "        y_test.extend([user_id]*X_test[-1].shape[0])\n",
    "        print(filepath[-2:],end=',')\n",
    "        return \n",
    "    data.groupby('user',as_index=False).apply(split_data)\n",
    "    return np.concatenate(X_train),np.concatenate(X_test),y_train,y_test\n",
    "\n",
    "def get_training_testing_sitting(window_size=10,\n",
    "                         base_window_size=10,n_user=300):\n",
    "    n_train = window_size*60//base_window_size\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    count = 0\n",
    "    i = 0\n",
    "    while i<len(X):\n",
    "        if X[i].shape[0]<n_train+30*6:\n",
    "            i+=1\n",
    "            continue\n",
    "        X_train.append(X[i][:n_train])\n",
    "        X_test.append(X[i][n_train:])\n",
    "        y_train.extend([y[i]]*X_train[-1].shape[0])\n",
    "        y_test.extend([y[i]]*X_test[-1].shape[0])\n",
    "        count+=1\n",
    "        i+=1\n",
    "        if count==n_user:\n",
    "            break\n",
    "    return np.concatenate(X_train),np.concatenate(X_test),y_train,y_test\n",
    "\n",
    "\n",
    "# directory = './data/walking_10/right_wrist/'\n",
    "# filepath1 = './data/all_walking_data_10.p'\n",
    "# if not os.path.isfile(filepath1):\n",
    "#     print(filepath1)\n",
    "#     data_col = []\n",
    "#     for f in os.listdir(directory):\n",
    "#         filepath = directory+f\n",
    "#         data  = pickle.load(open(filepath,'rb'))\n",
    "#         data_col.append(df)\n",
    "#     data = pd.concat(data_col)\n",
    "#     unique_users = data.user.unique()\n",
    "#     unique_users_dict = {u:i for i,u in enumerate(unique_users)}\n",
    "#     data['user_id'] = data['user'].apply(lambda a:unique_users_dict[a])\n",
    "#     data['time'] = data['window'].apply(lambda a:a[0])\n",
    "#     data['data'] = data['data'].apply(lambda a:np.array([np.array(b) for b in a]))\n",
    "#     data['data'] = data['data'].apply(lambda a:a[a[:,0].argsort(),:].reshape(1,-1,4))\n",
    "#     data['data'] = data['data'].apply(lambda a:a[:,:,1:])\n",
    "#     pickle.dump(data,open(filepath1,'wb'))\n",
    "# data = pd.DataFrame({'user':list(os.listdir(directory))})\n",
    "\n",
    "\n",
    "def get_test_score(window_size,base_window_size,n_user,model_save_path,n_timesteps,n_channels,test_lengths):\n",
    "    X_train,X_test,y_train,y_test = get_training_testing_sitting(window_size=window_size,base_window_size=base_window_size,n_user=n_user)\n",
    "    unique_users = np.unique(y_train+y_test)\n",
    "    unique_users_dict = {u:i for i,u in enumerate(unique_users)}\n",
    "    y_train = np.array([unique_users_dict[a] for a in y_train])\n",
    "    y_test = np.array([unique_users_dict[a] for a in y_test])\n",
    "    model_save_path1 = model_save_path+ str(window_size)+'/'\n",
    "    if not os.path.isdir(model_save_path1):\n",
    "        os.makedirs(model_save_path1)   \n",
    "    pickle.dump(unique_users_dict,open(model_save_path1+str(n_user)+'user_dict.p','wb'))   \n",
    "    filepath = model_save_path1+str(n_user)+'persons.hdf5'\n",
    "    model = get_trained_model(np.nan_to_num(X_train),y_train,n_timesteps,n_channels,window_size,filepath=filepath)\n",
    "    test_score = get_test_scores(model,np.nan_to_num(X_test),y_test,test_size=test_lengths,n_iter=1000,base_window_size=base_window_size)\n",
    "    test_score['train_user'] = n_user\n",
    "    test_score['train_lengths'] = window_size\n",
    "    del X_train\n",
    "    del X_test\n",
    "    del y_train\n",
    "    del y_test\n",
    "    return test_score\n",
    "\n",
    "\n",
    "base_window_size = 10\n",
    "Fs = 25\n",
    "n_timesteps = base_window_size*Fs\n",
    "n_channels = 3\n",
    "# window_sizes = [10,20,40,50]+list(np.arange(30,330,30))\n",
    "window_sizes = np.arange(330,700,30)\n",
    "window_sizes = np.arange(720,1200,30)\n",
    "test_lengths = [10,20] + list(np.arange(0,330,30)[1:])\n",
    "n_users = list(range(50,350,50))\n",
    "model_save_path = './models/'+str(base_window_size)+'/sitting/'\n",
    "result_save_path = './results/sitting/'\n",
    "if not os.path.isdir(result_save_path):\n",
    "    os.makedirs(result_save_path)\n",
    "if not os.path.isdir(model_save_path):\n",
    "    os.makedirs(model_save_path)\n",
    "results = []\n",
    "for window_size in window_sizes:\n",
    "    results = []\n",
    "    for n_user in n_users:\n",
    "        test_score = get_test_score(window_size,base_window_size,n_user,model_save_path,n_timesteps,n_channels,test_lengths)\n",
    "        results.append(test_score)\n",
    "        pickle.dump(pd.concat(results),open(result_save_path+str(window_size)+'.p','wb'))\n",
    "        print(n_user,end=',')\n",
    "    print(window_size,'done','-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = ['./models/10/sitting/'+str(i)+'/300persons.hdf5' for i in np.arange(180,720,30)]\n",
    "user_dicts = ['./models/10/sitting/'+str(i)+'/300user_dict.p' for i in np.arange(180,720,30)]\n",
    "\n",
    "users_all = [pickle.load(open(user_dict,'rb')) for user_dict in user_dicts]\n",
    "user_list = [list(a.keys()) for a in users_all]\n",
    "from functools import reduce\n",
    "all_users = list(set(list(reduce(lambda a,b:a+b,user_list))))\n",
    "\n",
    "models = [tf.keras.models.load_model(model_path) for model_path in model_paths]\n",
    "\n",
    "\n",
    "data_directory = './data/10/Sitting_test/'\n",
    "\n",
    "\n",
    "def get_user_data(user):\n",
    "    df = pickle.load(open(data_directory+user+'.p','rb'))\n",
    "    df['time'] = df['window'].apply(lambda a:a[0])\n",
    "    df['data'] = df['data'].apply(lambda a:np.array([np.array(b) for b in a]))\n",
    "    df['data'] = df['data'].apply(lambda a:a[a[:,0].argsort(),:].reshape(1,-1,4))\n",
    "    df['data'] = df['data'].apply(lambda a:a[:,:,1:])\n",
    "    df = df.sort_values('time').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "y_pred = []\n",
    "y_orig = []\n",
    "train_lengths = []\n",
    "for i,user in enumerate(all_users):\n",
    "    try:\n",
    "        df = get_user_data(user)\n",
    "        X_test = np.concatenate(list(df['data']))\n",
    "    except:\n",
    "        continue\n",
    "    for j,train_length in enumerate(np.arange(180,720,30)):\n",
    "        if user not in users_all[j]:\n",
    "            continue\n",
    "        pred = models[j].predict(X_test).argmax(axis=1)\n",
    "        orig = [users_all[j][user]]*len(pred)\n",
    "        y_pred.extend(list(pred))\n",
    "        y_orig.extend(list(orig))\n",
    "        train_lengths.extend([train_length]*len(orig))\n",
    "    print(i,end=',')\n",
    "test_dfs = pd.DataFrame({'prediction':y_pred,'original':y_orig,'train_lengths':train_lengths})\n",
    "pickle.dump(test_dfs,open('./data/temp.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dfs = pickle.load(open('./data/temp.p','rb'))\n",
    "\n",
    "def get_score(user,test_size,n_iter,base_window_size):\n",
    "    df = test_df[test_df.original==user]\n",
    "    score1 = []\n",
    "    score2 = []\n",
    "    test_lengths = []\n",
    "    for t in test_size:\n",
    "        n  = np.int64(t*60/base_window_size)\n",
    "        if n>df.shape[0]:\n",
    "            continue\n",
    "        y_true = [df['original'].values[0]]*n_iter\n",
    "        y_pred_majority = []\n",
    "#         y_pred_maxmean = []\n",
    "        for i in range(n_iter):\n",
    "            temp_df = df.sample(n,replace=False)\n",
    "            y_pred_majority.append(mode(temp_df['prediction'].values)[0][0])\n",
    "#             temp_df = np.mean(np.concatenate(list(temp_df['probability'])),axis=0)\n",
    "#             y_pred_maxmean.append(np.argmax(temp_df))\n",
    "\n",
    "\n",
    "        majority_score = accuracy_score(y_true,y_pred_majority)\n",
    "#         maxmean_score = accuracy_score(y_true,y_pred_maxmean)\n",
    "        score1.append(majority_score)\n",
    "#         score2.append(maxmean_score)\n",
    "        test_lengths.append(t)\n",
    "        \n",
    "    df = pd.DataFrame({'majority_score':score1,\n",
    "#                         'maxmean_score':score2,\n",
    "                        'test_lengths':test_lengths})\n",
    "#         print(df.loc[0])\n",
    "    return df\n",
    "\n",
    "\n",
    "test_size = [10,20] + list(np.arange(0,730,30)[1:])\n",
    "base_window_size = 10\n",
    "n_iter = 1000    \n",
    "\n",
    "results = []\n",
    "for tr_length in np.arange(180,720,30):\n",
    "    test_df = test_dfs[test_dfs.train_lengths==tr_length]\n",
    "\n",
    "    result  = Parallel(verbose=2,n_jobs=30)(delayed(get_score)(user,test_size,n_iter,base_window_size) for user in np.unique(test_df.original.values))\n",
    "    test_score = pd.concat(result)\n",
    "    acc_ = accuracy_score(test_df['original'],test_df['prediction'])\n",
    "\n",
    "    test_score = test_score.append(pd.DataFrame({'majority_score':[acc_],\n",
    "    #                                                     'maxmean_score':[acc_],\n",
    "                                                    'test_lengths':[0]}))\n",
    "    test_score = test_score.groupby('test_lengths',as_index=False).mean()\n",
    "    test_score['train_lengths'] = tr_length\n",
    "    results.append(test_score)\n",
    "    pickle.dump(pd.concat(results),open('./data/sitting_big_result.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data = pickle.load(open('./data/sitting_big_result.p','rb'))\n",
    "data = data[~data.train_lengths.isin([510,600,690])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.pivot_table(data,columns='train_lengths',index='test_lengths',values='majority_score',aggfunc='mean')\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(df,annot=True,fmt='.2f',cmap='Reds')\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lengths = data['train_lengths'].unique()\n",
    "plt.figure(figsize=(20,20))\n",
    "for tr_length in train_lengths:\n",
    "    df = data[data.train_lengths==tr_length]\n",
    "    plt.plot(df['test_lengths'],df['majority_score'],label=str(tr_length*6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
