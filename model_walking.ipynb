{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fresh-lobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[3], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "impossible-monthly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9900, 500, 3) (237149, 500, 3) 330 330\n",
      "Epoch 00044: early stopping\n",
      "0.05303030303030303 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 330 out of 330 | elapsed: 15.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16680, 500, 3) (223659, 500, 3) 278 278\n",
      "Epoch 00045: early stopping\n",
      "0.06534772182254196 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 278 out of 278 | elapsed: 13.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21870, 500, 3) (210774, 500, 3) 243 243\n",
      "Epoch 00046: early stopping\n",
      "0.09945130315500686 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 243 out of 243 | elapsed: 12.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23760, 500, 3) (194670, 500, 3) 198 198\n",
      "Epoch 00046: early stopping\n",
      "0.11026936026936027 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 198 out of 198 | elapsed: 10.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26400, 500, 3) (183175, 500, 3) 176 176\n",
      "Epoch 00046: early stopping\n",
      "0.12481060606060607 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 176 out of 176 | elapsed:  9.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25740, 500, 3) (167527, 500, 3) 143 143\n",
      "Epoch 00046: early stopping\n",
      "0.15345765345765347 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 143 out of 143 | elapsed:  7.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25410, 500, 3) (154994, 500, 3) 121 121\n",
      "Epoch 00047: early stopping\n",
      "0.16706021251475797 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 121 out of 121 | elapsed:  6.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24240, 500, 3) (142689, 500, 3) 101 101\n",
      "Epoch 00049: early stopping\n",
      "0.19203795379537955 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 101 out of 101 | elapsed:  5.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22680, 500, 3) (131309, 500, 3) 84 84\n",
      "Epoch 00049: early stopping\n",
      "0.2431657848324515 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  84 | elapsed:  4.5min remaining:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done  84 out of  84 | elapsed:  4.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500, 500, 3) (123956, 500, 3) 75 75\n",
      "Epoch 00051: early stopping\n",
      "0.26911111111111113 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  66 out of  75 | elapsed:  3.7min remaining:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19800, 500, 3) (112710, 500, 3) 60 60\n",
      "Epoch 00058: early stopping\n",
      "0.36893939393939396 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  60 | elapsed:  2.5min remaining:   55.1s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16920, 500, 3) (102168, 500, 3) 47 47\n",
      "Epoch 00058: early stopping\n",
      "0.38800236406619387 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  47 | elapsed:  2.3min remaining:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  47 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15990, 500, 3) (96412, 500, 3) 41 41\n",
      "Epoch 00060: early stopping\n",
      "0.4283927454659162 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  41 | elapsed:  1.2min remaining:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  41 | elapsed:  2.2min remaining:   18.6s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  41 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13860, 500, 3) (88739, 500, 3) 33 33\n",
      "Epoch 00067: early stopping\n",
      "0.5274170274170275 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  33 | elapsed:  1.2min remaining: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  33 | elapsed:  1.2min remaining:   48.1s\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13050, 500, 3) (84346, 500, 3) 29 29\n",
      "Epoch 00072: early stopping\n",
      "0.5344827586206896 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  29 | elapsed:  1.2min remaining:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  29 | elapsed:  1.9min remaining:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11520, 500, 3) (78906, 500, 3) 24 24\n",
      "Epoch 00076: early stopping\n",
      "0.5924479166666666 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  24 | elapsed:  1.2min remaining:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  24 | elapsed:  1.2min remaining:   36.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10710, 500, 3) (75282, 500, 3) 21 21\n",
      "Epoch 00076: early stopping\n",
      "0.6251167133520075 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  21 | elapsed:  1.0min remaining:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  21 | elapsed:  1.1min remaining:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10260, 500, 3) (72606, 500, 3) 19 19\n",
      "Epoch 00072: early stopping\n",
      "0.6237816764132553 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  19 | elapsed:   43.2s remaining:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  19 | elapsed:  1.0min remaining:   36.2s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10830, 500, 3) (72036, 500, 3) 19 19\n",
      "Epoch 00078: early stopping\n",
      "0.6514312096029548 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  19 | elapsed:   43.5s remaining:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  19 | elapsed:  1.0min remaining:   35.5s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9600, 500, 3) (67983, 500, 3) 16 16\n",
      "Epoch 00081: early stopping\n",
      "0.5973958333333333 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  16 | elapsed:   42.4s remaining:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  16 | elapsed:   58.7s remaining:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10080, 500, 3) (67503, 500, 3) 16 16\n",
      "Epoch 00093: early stopping\n",
      "0.6517857142857143 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  16 | elapsed:   43.3s remaining:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  16 | elapsed:   58.0s remaining:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8580, 500, 3) (63137, 500, 3) 13 13\n",
      "Epoch 00093: early stopping\n",
      "0.7062937062937062 220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  13 | elapsed:   46.3s remaining:   29.0s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6210, 500, 3) (57507, 500, 3) 9 9\n",
      "Epoch 00093: early stopping\n",
      "0.7053140096618358 230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:   40.7s remaining:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   9 | elapsed:   42.7s remaining:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5760, 500, 3) (55838, 500, 3) 8 8\n",
      "Epoch 00138: early stopping\n",
      "0.8237847222222222 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:   42.8s remaining:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Conv1D,BatchNormalization,Dropout,Input,MaxPooling1D,Flatten,Dense,Input,Activation,GRU\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import Parallel,delayed\n",
    "from scipy.stats import mode\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_model(input_shape=(500,3),n_classes=1):\n",
    "    model =  Sequential()\n",
    "    model.add(Conv1D(128,2,input_shape=input_shape,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Conv1D(128,2,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "#     model.add(Conv1D(128,2,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "#     model.add(MaxPooling1D(2))\n",
    "#     model.add(Conv1D(128,2,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "#     model.add(MaxPooling1D(2))\n",
    "    model.add(Activation('tanh'))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(GRU(128,return_sequences=True,activation='tanh'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Dense(n_classes,activation='softmax'))\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),optimizer='adam')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_score(df,test_size,n_iter,base_window_size):\n",
    "    score1 = []\n",
    "    score2 = []\n",
    "    test_lengths = []\n",
    "    for t in test_size:\n",
    "        n  = np.int64(t*60/base_window_size)\n",
    "        if n>df.shape[0]:\n",
    "            continue\n",
    "        y_true = [df['original'].values[0]]*n_iter\n",
    "        y_pred_majority = []\n",
    "        y_pred_maxmean = []\n",
    "        for i in range(n_iter):\n",
    "            temp_df = df.sample(n,replace=False)\n",
    "            y_pred_majority.append(mode(temp_df['prediction'].values)[0][0])\n",
    "            temp_df = np.mean(np.concatenate(list(temp_df['probability'])),axis=0)\n",
    "            y_pred_maxmean.append(np.argmax(temp_df))\n",
    "        \n",
    "            \n",
    "        majority_score = accuracy_score(y_true,y_pred_majority)\n",
    "        maxmean_score = accuracy_score(y_true,y_pred_maxmean)\n",
    "        score1.append(majority_score)\n",
    "        score2.append(maxmean_score)\n",
    "        test_lengths.append(t)\n",
    "    return pd.DataFrame({'user':[df['original'].values[0]]*len(score1),\n",
    "                        'majority_score':score1,\n",
    "                        'maxmean_score':score2,\n",
    "                        'test_lengths':test_lengths})\n",
    "\n",
    "\n",
    "def get_test_scores(model,X_test,y_test,test_size=None,n_iter=1000,base_window_size=20):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred1 = y_pred.argmax(axis=1)\n",
    "    test_df = pd.DataFrame({'prediction':y_pred1,'original':y_test,'probability':list(y_pred)})\n",
    "    test_df['probability'] = test_df['probability'].apply(lambda a:a.reshape(1,-1)) \n",
    "    if test_size is None:\n",
    "        test_size = np.arange(1,120,1)\n",
    "    result  = Parallel(n_jobs=-1,verbose=2)(delayed(get_score)(df,test_size,n_iter,base_window_size) for i,df in test_df.groupby('original',as_index=False))\n",
    "    test_score = pd.concat(result)\n",
    "    return test_score,test_df\n",
    "\n",
    "\n",
    "\n",
    "def get_trained_model(X_train,y_train,n_timesteps,n_channels,window_size):\n",
    "    n_classes = len(np.unique(y_train))\n",
    "    model =  get_model(input_shape=(n_timesteps,n_channels),n_classes=n_classes)\n",
    "    model.summary()\n",
    "#     filepath = './models/walking/person_estimator_mperf_base_20_seconds_train_'+str(window_size)+'_seconds.hdf5'\n",
    "#     checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='min',save_weights_only=False)\n",
    "#     es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=40)\n",
    "#     callbacks_list = [es,checkpoint]\n",
    "# #     train_x,test_x,train_y,test_y = train_test_split(X_train,y_train,test_size=.2,stratify=y_train)\n",
    "#     train_x,val_x,train_y,val_y = train_test_split(X_train,y_train,test_size=.2,stratify=y_train)\n",
    "#     history = model.fit(train_x,train_y,validation_data=(val_x,val_y), epochs=200, batch_size=300,verbose=0,\n",
    "#           callbacks=callbacks_list,shuffle=True)\n",
    "#     model.load_weights(filepath)\n",
    "#     y_pred = model.predict(test_x).argmax(axis=1)\n",
    "\n",
    "#     from sklearn.metrics import classification_report\n",
    "\n",
    "#     print(accuracy_score(test_y,y_pred),window_size)\n",
    "#     return model\n",
    "\n",
    "\n",
    "def get_training_testing(window_size=10,\n",
    "                         base_window_size=20):\n",
    "    n_train = window_size*60//base_window_size\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    def split_data(df):\n",
    "        if df.shape[0]<n_train*3:\n",
    "            return \n",
    "        df = df.sort_values('time').reset_index(drop=True)\n",
    "        user_id = df.user.values[0]\n",
    "        X_train.append(np.concatenate(list(df[:n_train]['data'].values)))\n",
    "        X_test.append(np.concatenate(list(df[n_train:]['data'].values)))\n",
    "        y_train.extend([user_id]*X_train[-1].shape[0])\n",
    "        y_test.extend([user_id]*X_test[-1].shape[0])\n",
    "        return \n",
    "    data.groupby('user',as_index=False).apply(split_data)\n",
    "    return np.concatenate(X_train),np.concatenate(X_test),y_train,y_test\n",
    "\n",
    "\n",
    "directory = './data/right_wrist/'\n",
    "filepath1 = './data/all_walking_data.p'\n",
    "if not os.path.isfile(filepath1):\n",
    "    print(filepath1)\n",
    "    data_col = []\n",
    "    for f in os.listdir(directory):\n",
    "        filepath = directory+f\n",
    "        df  = pickle.load(open(filepath,'rb'))\n",
    "        data_col.append(df)\n",
    "    data = pd.concat(data_col)\n",
    "    unique_users = data.user.unique()\n",
    "    unique_users_dict = {u:i for i,u in enumerate(unique_users)}\n",
    "    data['user_id'] = data['user'].apply(lambda a:unique_users_dict[a])\n",
    "    data['time'] = data['window'].apply(lambda a:a[0])\n",
    "    data['data'] = data['data'].apply(lambda a:np.array([np.array(b) for b in a]))\n",
    "    data['data'] = data['data'].apply(lambda a:a[a[:,0].argsort(),:].reshape(1,-1,4))\n",
    "    data['data'] = data['data'].apply(lambda a:a[:,:,1:])\n",
    "    pickle.dump(data,open(filepath1,'wb'))\n",
    "\n",
    "\n",
    "base_window_size = 20\n",
    "Fs = 25\n",
    "n_timesteps = base_window_size*Fs\n",
    "n_channels = 3\n",
    "window_sizes = np.arange(10,250,10)\n",
    "test_lengths = np.arange(1,180,2)\n",
    "results = []\n",
    "for window_size in window_sizes:\n",
    "    data = pickle.load(open(filepath1,'rb'))\n",
    "    X_train,X_test,y_train,y_test = get_training_testing(window_size=window_size)\n",
    "    unique_users = np.unique(y_train+y_test)\n",
    "    unique_users_dict = {u:i for i,u in enumerate(unique_users)}\n",
    "    y_train = np.array([unique_users_dict[a] for a in y_train])\n",
    "    y_test = np.array([unique_users_dict[a] for a in y_test])\n",
    "    print(X_train.shape,X_test.shape,len(np.unique(y_train)),len(np.unique(y_test)))\n",
    "    model = get_trained_model(X_train,y_train,n_timesteps,n_channels,window_size)\n",
    "    test_score,test_df = get_test_scores(model,X_test,y_test,test_size=test_lengths,n_iter=1000,base_window_size=20)\n",
    "    results.append([window_size,test_score,test_df,y_test,unique_users_dict])\n",
    "    pickle.dump(results,open('./data/walking_results.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score.groupby('test_lengths').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-playing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score.groupby('test_lengths').mean()[['maxmean_score','majority_score']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-grounds",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
