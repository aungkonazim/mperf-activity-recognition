{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from pyspark.sql.types import StructField, StructType, DoubleType,MapType, StringType,ArrayType, FloatType, TimestampType, IntegerType\n",
    "from cerebralcortex.core.datatypes import DataStream\n",
    "from cerebralcortex.core.metadata_manager.stream.metadata import Metadata, DataDescriptor, \\\n",
    "ModuleMetadata\n",
    "from scipy import signal\n",
    "from scipy.interpolate import interp1d\n",
    "from cerebralcortex import Kernel\n",
    "from scipy.stats import skew,kurtosis,mode\n",
    "CC = Kernel(\"/home/jupyter/cc3_conf/\", study_name='mperf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampling mperf data to 20Hz and computes the magnitude and applies activity recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import tensorflow \n",
    "\n",
    "def interpolate_acl(a,window_size=10,fs_now=25,fs_new=20):\n",
    "    x_now = np.linspace(0,window_size,window_size*fs_now)\n",
    "    f = interp1d(x_now,a,axis=0,fill_value='extrapolate')\n",
    "    x_new = np.linspace(0,window_size,window_size*fs_new)\n",
    "    return f(x_new)\n",
    "\n",
    "class ModelWrapperPickable:\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def __getstate__(self):\n",
    "        model_str = ''\n",
    "        with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:\n",
    "            tensorflow.keras.models.save_model(self.model, fd.name, overwrite=True)\n",
    "            model_str = fd.read()\n",
    "        d = { 'model_str': model_str }\n",
    "        return d\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:\n",
    "            fd.write(state['model_str'])\n",
    "            fd.flush()\n",
    "            self.model = tensorflow.keras.models.load_model(fd.name)\n",
    "\n",
    "\n",
    "def isDatapointsWithinRange(red,infrared,green):\n",
    "        red = np.asarray(red, dtype=np.float32)\n",
    "        infrared = np.asarray(infrared, dtype=np.float32)\n",
    "        green = np.asarray(green, dtype=np.float32)\n",
    "        a =  len(np.where((red >= 20000)& (red<=200000))[0]) < .33*10*25\n",
    "        b = len(np.where((infrared >= 80000)& (infrared<=230000))[0]) < .33*10*25\n",
    "        c = len(np.where((green >= 500)& (green<=20000))[0]) < .33*10*25\n",
    "        if a and b and c:\n",
    "            return False\n",
    "        return True            \n",
    "\n",
    "            \n",
    "def compute_quality(red,infrared,green):\n",
    "        \"\"\"\n",
    "        :param window: a window containing list of DataPoints\n",
    "        :return: an integer reptresenting the status of the window 0= attached, 1 = not attached\n",
    "        \"\"\"\n",
    "        if len(red)==0:\n",
    "            return 'Not Worn' #not attached\n",
    "        if not isDatapointsWithinRange(red,infrared,green):\n",
    "            return 'Not Worn'\n",
    "        red_mean = np.mean(red)\n",
    "        ir_mean = np.mean(infrared)\n",
    "        green_mean = np.mean(green)\n",
    "        if red_mean < 5000 and ir_mean < 5000:\n",
    "            return 'Not Worn'\n",
    "        if not (red_mean>green_mean and ir_mean>red_mean):\n",
    "            return 'Not Worn'\n",
    "        diff = 30000\n",
    "        if red_mean<130000:\n",
    "            diff = 10000\n",
    "        if not red_mean - green_mean > diff:\n",
    "            return 'Not Worn'\n",
    "        if not ir_mean - red_mean >diff:\n",
    "            return 'Not Worn'\n",
    "        return 'Worn'            \n",
    "            \n",
    "\n",
    "def compute_magnitude_and_activity(data,\n",
    "                                   Fs = 25,\n",
    "                                   window_size = 10,\n",
    "                                   stream_name = 'org.md2k.feature.motionsensehrv.decoded.rightwrist.all',\n",
    "                                   new_Fs = 20,\n",
    "                                   filename1 = './models/activity_estimator_both_magnitude.hdf5',\n",
    "                                   filename2 = './models/activity_estimator_wisdm_magnitude.hdf5',\n",
    "                                   filename3 = './models/activity_estimator_dalia_magnitude.hdf5'):\n",
    "            \n",
    "    model = load_model(filename1)\n",
    "\n",
    "    model_wrapper= ModelWrapperPickable(model)\n",
    "\n",
    "\n",
    "    model_wisdm = load_model(filename2)\n",
    "\n",
    "    model_wrapper_wisdm= ModelWrapperPickable(model_wisdm)\n",
    "    \n",
    "    model_dalia = load_model(filename3)\n",
    "\n",
    "    model_wrapper_dalia = ModelWrapperPickable(model_dalia)\n",
    "\n",
    "\n",
    "    data = data.select('localtime','timestamp','aclx','acly','aclz','user','version','red','infrared','green')\n",
    "\n",
    "    data = data.withColumn('magnitude',F.sqrt(F.pow(F.col('aclx'),2)+F.pow(F.col('acly'),2)+F.pow(F.col('aclz'),2))).drop('aclx','acly','aclz')\n",
    "\n",
    "    data = data.withColumn('time',F.col('timestamp').cast('double'))\n",
    "\n",
    "    data = data.withColumn('magnitude_time',F.array('time','magnitude')).drop('time','magnitude')\n",
    "\n",
    "    groupbycols = ['user','version',\n",
    "                   F.window('timestamp',windowDuration=str(window_size)+' seconds', startTime='0 seconds')]\n",
    "    data_windowed_10 = data.groupBy(groupbycols).agg(F.collect_list('magnitude_time'),\n",
    "                                                     F.collect_list('localtime'),\n",
    "                                                    F.collect_list('red'),\n",
    "                                                    F.collect_list('infrared'),\n",
    "                                                    F.collect_list('green'))\n",
    "\n",
    "    data_windowed_10 = data_windowed_10.withColumnRenamed('collect_list(magnitude_time)','magnitude_time')\n",
    "    data_windowed_10 = data_windowed_10.withColumnRenamed('collect_list(localtime)','localtime')\n",
    "    \n",
    "    data_windowed_10 = data_windowed_10.withColumnRenamed('collect_list(red)','red')\n",
    "    data_windowed_10 = data_windowed_10.withColumnRenamed('collect_list(infrared)','infrared')\n",
    "    data_windowed_10 = data_windowed_10.withColumnRenamed('collect_list(green)','green')\n",
    "\n",
    "    qfunction = F.udf(compute_quality,StringType())\n",
    "    data_windowed_10 = data_windowed_10.withColumn('quality',qfunction(data_windowed_10['red'],data_windowed_10['infrared'],data_windowed_10['green']))\n",
    "\n",
    "    data_windowed_10 = data_windowed_10.drop('red','infrared','green')\n",
    "    \n",
    "    data_windowed_10 = data_windowed_10.filter(F.col('quality')=='Worn').drop('quality')\n",
    "\n",
    "    \n",
    "    data_windowed_10 = data_windowed_10.withColumn('localtime',F.col('localtime').getItem(0))\n",
    "\n",
    "    data_windowed_10 = data_windowed_10.withColumn('length',F.size('magnitude_time'))\n",
    "\n",
    "    data_windowed_10 = data_windowed_10.filter(F.col('length')==window_size*Fs).drop('length')\n",
    "\n",
    "    data_windowed_10 = data_windowed_10.withColumn('timestamp',F.col('window').start).withColumn('start',F.col('window').start).withColumn('end',F.col('window').end).drop('window')\n",
    "\n",
    "    data_windowed_10  = data_windowed_10.withColumn('day',F.date_format('localtime',\"yyyyMMdd\"))\n",
    "\n",
    "    final_activity_list = ['Brushing','Cycling','Sports','Eating','Driving',\n",
    "                           'Exercise','Sitting','Stairs','Standing','Walking']\n",
    "    final_activity_dict = {a:i for i,a in enumerate(final_activity_list)}\n",
    "    final_activity_dict_reverse = {i:a for i,a in enumerate(final_activity_list)}\n",
    "\n",
    "    activity_list_wisdm = ['Sitting','Stairs','Jogging','Typing','Standing','Walking','Brushing','Eating','Drinking','Kicking',\n",
    "                    'Playing Catch','Dribbling','Writing','Clapping','Folding Clothes']\n",
    "    activity_list_dalia = ['Driving','Sitting','Stairs','Walking']\n",
    "#     print(data_windowed_10.schema)\n",
    "    schema = StructType(list(data_windowed_10.schema)[:2]+list(data_windowed_10.schema)[3:]+[StructField(\"magnitude\", ArrayType(DoubleType())),\n",
    "                                                                                            StructField(\"prediction\", StringType()),\n",
    "                                                                                            StructField(\"prediction_wisdm\", StringType()),\n",
    "                                                                                            StructField(\"prediction_dalia\", StringType()),\n",
    "                                                                                            StructField(\"mean\", DoubleType()),\n",
    "                                                                                            StructField(\"std\", DoubleType()),\n",
    "                                                                                            StructField(\"skew\", DoubleType()),\n",
    "                                                                                            StructField(\"kurtosis\", DoubleType())])\n",
    "#     print(schema)\n",
    "\n",
    "    \n",
    "    def smooth_predictions(df):\n",
    "        if df.shape[0]<3:\n",
    "            return pd.DataFrame([],columns=columns)\n",
    "        for name in ['prediction','prediction_wisdm','prediction_dalia']:\n",
    "            y_activities = list(df[name])\n",
    "            m_act = mode(y_activities)[0][0]\n",
    "            df[name] = [m_act]*df.shape[0]\n",
    "        return df\n",
    "\n",
    "    columns = [a.name for a in schema.fields]\n",
    "    @pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "    def interpolate_acl_magnitude(df):\n",
    "        df['magnitude_time'] = df['magnitude_time'].apply(lambda b:np.array([np.array(a) for a in b]).reshape(window_size*Fs,2))\n",
    "        df['magnitude_time'] = df['magnitude_time'].apply(lambda a:a[a[:,0].argsort()])\n",
    "        df['magnitude_time'] = df['magnitude_time'].apply(lambda a:a[:,1].reshape(window_size*Fs,1))\n",
    "        df['magnitude'] = df['magnitude_time'].apply(lambda a:interpolate_acl(a).reshape(1,window_size*new_Fs,1))\n",
    "        X = np.concatenate(list(df['magnitude']))\n",
    "        y_pred = model_wrapper.model.predict(X).argmax(axis=1)\n",
    "        df['prediction'] = list(y_pred.reshape(-1))\n",
    "        df['prediction'] = df['prediction'].apply(lambda a:final_activity_dict_reverse[a])\n",
    "\n",
    "        y_pred = model_wrapper_wisdm.model.predict(X).argmax(axis=1)\n",
    "        df['prediction_wisdm'] = list(y_pred.reshape(-1))\n",
    "        df['prediction_wisdm'] = df['prediction_wisdm'].apply(lambda a:activity_list_wisdm[a])\n",
    "        \n",
    "        y_pred = model_wrapper_dalia.model.predict(X).argmax(axis=1)\n",
    "        df['prediction_dalia'] = list(y_pred.reshape(-1))\n",
    "        df['prediction_dalia'] = df['prediction_dalia'].apply(lambda a:activity_list_dalia[a])\n",
    "        \n",
    "        df['magnitude'] = df['magnitude'].apply(lambda a:a.reshape(-1)) \n",
    "        df['mean'] = df['magnitude'].apply(lambda a:np.mean(a))\n",
    "        df['std'] = df['magnitude'].apply(lambda a:np.std(a))\n",
    "        df['skew'] = df['magnitude'].apply(lambda a:skew(a))\n",
    "        df['kurtosis'] = df['magnitude'].apply(lambda a:kurtosis(a))\n",
    "        df = df[columns]\n",
    "        df = df.groupby(pd.Grouper(key='timestamp',freq=str(3*window_size)+'S'),as_index=False).apply(smooth_predictions)\n",
    "        return df\n",
    "\n",
    "    data_interpolated = data_windowed_10.groupBy(['user','version','day']).apply(interpolate_acl_magnitude)\n",
    "    schema = data_interpolated.schema\n",
    "    stream_metadata = Metadata()\n",
    "    stream_metadata.set_name(stream_name+'.activity.all').set_description(\"Activity Computed\")\n",
    "    for field in schema.fields:\n",
    "        stream_metadata.add_dataDescriptor(\n",
    "            DataDescriptor().set_name(str(field.name)).set_type(str(field.dataType))\n",
    "        )\n",
    "    stream_metadata.add_module(\n",
    "        ModuleMetadata().set_name(\"activity datastream\") \\\n",
    "        .set_attribute(\"url\", \"https://md2k.org\").set_author(\n",
    "            \"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "    stream_metadata.is_valid()\n",
    "    data_interpolated.printSchema()\n",
    "    ds = DataStream(data=data_interpolated,metadata=stream_metadata)\n",
    "    return ds\n",
    "# CC.save_stream(ds,overwrite=True)\n",
    "\n",
    "stream_name = 'org.md2k.feature.motionsensehrv.decoded.rightwrist.all'\n",
    "data = CC.get_stream(stream_name)\n",
    "data_activity = compute_magnitude_and_activity(data,stream_name=stream_name)\n",
    "CC.save_stream(data_activity,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = CC.get_stream('org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity.all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupBy('prediction_dalia').count().show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_data = CC.get_stream('org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity')\n",
    "\n",
    "count_data = right_data.select('user','prediction','day').groupBy(['user','prediction','day']).count()\n",
    "df = count_data.toPandas()\n",
    "import pickle\n",
    "pickle.dump(df,open('./data/right_wrist_count.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_data = CC.get_stream('org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity')\n",
    "\n",
    "count_data = right_data.select('user','prediction_wisdm','day').groupBy(['user','prediction_wisdm','day']).count()\n",
    "df = count_data.toPandas()\n",
    "import pickle\n",
    "pickle.dump(df,open('./data/right_wrist_count_wisdm.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "df = pickle.load(open('./data/right_wrist_count.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['prediction'] = df['prediction_wisdm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count'] = df['count'].apply(lambda a:(a*10)/3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_walking = df[df['prediction']=='Walking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(df_walking[['user','count']].groupby('user').quantile(.99)['count'],20)\n",
    "plt.title('Maximum walking hours for a single day')\n",
    "plt.xlabel('Hours')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./images/Maximumwalk.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_walking.groupby('user').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_mean = df.groupby(['user','prediction'],as_index=False).mean()\n",
    "plt.rcParams.update({'font.size':20})\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.boxplot(x='prediction',y='count',data=df_user_mean)\n",
    "plt.xticks(rotation='60')\n",
    "plt.ylabel('Hours')\n",
    "plt.savefig('./images/user_mean_per_day.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(df_user_mean['count'][df_user_mean['prediction'].isin(['Walking','Stairs','Sports','Exercise'])],300,density=True)\n",
    "plt.xlim([0,2])\n",
    "plt.title('Moving Hours per day distribution')\n",
    "plt.xlabel('Hours')\n",
    "plt.savefig('./images/moving_hours_per_day.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_activity_list = ['Brushing','Cycling','Sports','Eating','Driving',\n",
    "#                        'Exercise','Sitting','Stairs','Standing','Walking']\n",
    "def percentage(df):\n",
    "    activities = np.unique(df['prediction'])\n",
    "    result  = []\n",
    "    for a in activities:\n",
    "        result.append(100*df['count'][df['prediction']==a].values[0]/df['count'].sum())\n",
    "    users = [df.user.values[0]]*len(result)\n",
    "    return pd.DataFrame({'activities':activities,'user':users,'percentage':result})\n",
    "\n",
    "df_user_percentage = df_user_mean.groupby('user',as_index=False).apply(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size':20})\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.boxplot(x='activities',y='percentage',data=df_user_percentage)\n",
    "plt.xticks(rotation=60)\n",
    "plt.savefig('./images/user_percentage_per_day.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_name = 'org.md2k.feature.motionsensehrv.decoded.leftwrist.all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CC.get_stream(stream_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select('user').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_activity.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "61692/(25*3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_activity.show(4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "High Performance CC3.3",
   "language": "python",
   "name": "cc33_high_performance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
