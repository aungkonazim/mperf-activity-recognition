{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cerebralcortex/kessel_jupyter_virtualenv/cc33/lib64/python3.6/site-packages/cerebralcortex/core/data_manager/raw/data.py:67: DeprecationWarning: pyarrow.hdfs.connect is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  self.fs = pa.hdfs.connect(self.hdfs_ip, self.hdfs_port)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from pyspark.sql.types import StructField, StructType, DoubleType,MapType, StringType,ArrayType, FloatType, TimestampType, IntegerType\n",
    "from cerebralcortex.core.datatypes import DataStream\n",
    "from cerebralcortex.core.metadata_manager.stream.metadata import Metadata, DataDescriptor, \\\n",
    "ModuleMetadata\n",
    "from scipy import signal\n",
    "from scipy.interpolate import interp1d\n",
    "from cerebralcortex import Kernel\n",
    "from scipy.stats import skew,kurtosis,mode\n",
    "CC = Kernel(\"/home/jupyter/cc3_conf/\", study_name='moral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accelerometer--org.md2k.motionsense--motion_sense--left_wrist',\n",
       " 'accelerometer--org.md2k.motionsense--motion_sense--right_wrist',\n",
       " 'accelerometer--org.md2k.motionsense--motion_sense--right_wrist.activity.all.three',\n",
       " 'annotation--org.md2k.motionsense--motion_sense--moral_brushing_flossing',\n",
       " 'gyroscope--org.md2k.motionsense--motion_sense--left_wrist',\n",
       " 'gyroscope--org.md2k.motionsense--motion_sense--right_wrist']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CC.list_streams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-----------+----------+-----------+-----------------------+----+-------+\n",
      "|timestamp              |x          |y         |z          |localtime              |user|version|\n",
      "+-----------------------+-----------+----------+-----------+-----------------------+----+-------+\n",
      "|2017-03-16 19:55:51.584|-0.23120117|-0.9250488|-0.13598633|2017-03-16 13:55:51.584|820c|1      |\n",
      "|2017-03-16 19:55:51.644|-0.23266602|-0.9182129|-0.14160156|2017-03-16 13:55:51.644|820c|1      |\n",
      "|2017-03-16 19:55:51.704|-0.23046875|-0.9152832|-0.1352539 |2017-03-16 13:55:51.704|820c|1      |\n",
      "|2017-03-16 19:55:51.764|-0.2290039 |-0.9172363|-0.14428711|2017-03-16 13:55:51.764|820c|1      |\n",
      "|2017-03-16 19:55:51.824|-0.2241211 |-0.9111328|-0.13647461|2017-03-16 13:55:51.824|820c|1      |\n",
      "+-----------------------+-----------+----------+-----------+-----------------------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "['user', 'version', 'localtime', 'timestamp', 'start', 'end', 'day', 'magnitude', 'prediction', 'prediction_wisdm', 'prediction_dalia', 'mean', 'std', 'skew', 'kurtosis']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cerebralcortex/kessel_jupyter_virtualenv/cc33/lib64/python3.6/site-packages/pyspark/sql/pandas/group_ops.py:76: UserWarning: It is preferred to use 'applyInPandas' over this API. This API will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  \"more details.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user: string (nullable = true)\n",
      " |-- version: integer (nullable = false)\n",
      " |-- localtime: timestamp (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- start: timestamp (nullable = true)\n",
      " |-- end: timestamp (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- magnitude: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- prediction: string (nullable = true)\n",
      " |-- prediction_wisdm: string (nullable = true)\n",
      " |-- prediction_dalia: string (nullable = true)\n",
      " |-- mean: double (nullable = true)\n",
      " |-- std: double (nullable = true)\n",
      " |-- skew: double (nullable = true)\n",
      " |-- kurtosis: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tempfile\n",
    "import tensorflow \n",
    "\n",
    "def interpolate_acl(a,window_size=20,fs_now=25,fs_new=20):\n",
    "    x_now = np.linspace(0,window_size,a.shape[0])\n",
    "    f = interp1d(x_now,a,axis=0,fill_value='extrapolate')\n",
    "    x_new = np.linspace(0,window_size,window_size*fs_new)\n",
    "    return f(x_new)\n",
    "\n",
    "class ModelWrapperPickable:\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def __getstate__(self):\n",
    "        model_str = ''\n",
    "        with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:\n",
    "            tensorflow.keras.models.save_model(self.model, fd.name, overwrite=True)\n",
    "            model_str = fd.read()\n",
    "        d = { 'model_str': model_str }\n",
    "        return d\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:\n",
    "            fd.write(state['model_str'])\n",
    "            fd.flush()\n",
    "            self.model = tensorflow.keras.models.load_model(fd.name)\n",
    "\n",
    "            \n",
    "\n",
    "def compute_magnitude_and_activity(data,\n",
    "                                   Fs = 16,\n",
    "                                   window_size = 20,\n",
    "                                   stream_name = 'org.md2k.feature.motionsensehrv.decoded.rightwrist.all',\n",
    "                                   new_Fs = 20,\n",
    "                                   acceptable_percentage = .8,\n",
    "                                   filename1 = './models/activity_estimator_both_study_magnitude_final_5_labels.hdf5',\n",
    "                                   filename2 = './models/activity_estimator_wisdm_magnitude_final_5_labels.hdf5',\n",
    "                                   filename3 = './models/activity_estimator_dalia_magnitude_final_5_labels.hdf5'):\n",
    "            \n",
    "    model = load_model(filename1)\n",
    "\n",
    "    model_wrapper= ModelWrapperPickable(model)\n",
    "\n",
    "\n",
    "    model_wisdm = load_model(filename2)\n",
    "\n",
    "    model_wrapper_wisdm= ModelWrapperPickable(model_wisdm)\n",
    "    \n",
    "    model_dalia = load_model(filename3)\n",
    "\n",
    "    model_wrapper_dalia = ModelWrapperPickable(model_dalia)\n",
    "\n",
    "\n",
    "    data = data.select('localtime','timestamp','x','y','z','user','version')\n",
    "\n",
    "    data = data.withColumn('magnitude',F.sqrt(F.pow(F.col('x'),2)+F.pow(F.col('y'),2)+F.pow(F.col('z'),2))).drop('x','y','z')\n",
    "\n",
    "    data = data.withColumn('time',F.col('timestamp').cast('double'))\n",
    "\n",
    "    data = data.withColumn('magnitude_time',F.array('time','magnitude')).drop('time','magnitude')\n",
    "\n",
    "    groupbycols = ['user','version',\n",
    "                   F.window('timestamp',windowDuration=str(window_size)+' seconds', startTime='0 seconds',slideDuration=str(window_size//2)+' seconds')]\n",
    "    data_windowed_10 = data.groupBy(groupbycols).agg(F.collect_list('magnitude_time'),\n",
    "                                                     F.collect_list('localtime'))\n",
    "\n",
    "    data_windowed_10 = data_windowed_10.withColumnRenamed('collect_list(magnitude_time)','magnitude_time')\n",
    "    data_windowed_10 = data_windowed_10.withColumnRenamed('collect_list(localtime)','localtime')\n",
    "    \n",
    "#     data_windowed_10 = data_windowed_10.withColumnRenamed('collect_list(red)','red')\n",
    "#     data_windowed_10 = data_windowed_10.withColumnRenamed('collect_list(infrared)','infrared')\n",
    "#     data_windowed_10 = data_windowed_10.withColumnRenamed('collect_list(green)','green')\n",
    "\n",
    "#     qfunction = F.udf(compute_quality,StringType())\n",
    "#     data_windowed_10 = data_windowed_10.withColumn('quality',qfunction(data_windowed_10['red'],data_windowed_10['infrared'],data_windowed_10['green']))\n",
    "\n",
    "#     data_windowed_10 = data_windowed_10.drop('red','infrared','green')\n",
    "    \n",
    "#     data_windowed_10 = data_windowed_10.filter(F.col('quality')=='Worn').drop('quality')\n",
    "\n",
    "    \n",
    "    data_windowed_10 = data_windowed_10.withColumn('localtime',F.col('localtime').getItem(0))\n",
    "\n",
    "    data_windowed_10 = data_windowed_10.withColumn('length',F.size('magnitude_time'))\n",
    "\n",
    "    data_windowed_10 = data_windowed_10.filter(F.col('length')>=acceptable_percentage*window_size*Fs).drop('length')\n",
    "\n",
    "    data_windowed_10 = data_windowed_10.withColumn('timestamp',F.col('window').start).withColumn('start',F.col('window').start).withColumn('end',F.col('window').end).drop('window')\n",
    "\n",
    "    data_windowed_10  = data_windowed_10.withColumn('day',F.date_format('localtime',\"yyyyMMdd\"))\n",
    "    \n",
    "#     data_windowed_10.show(1,False)\n",
    "#     data_windowed_10.printSchema()\n",
    "    final_activity_list = ['Stationery','Stairs','Exercise','Walking','Sports']\n",
    "    final_activity_dict = {a:i for i,a in enumerate(final_activity_list)}\n",
    "    final_activity_dict_reverse = {i:a for i,a in enumerate(final_activity_list)}\n",
    "    activity_list_wisdm = ['Stationery','Stairs','Exercise','Walking','Sports']\n",
    "    activity_list_dalia = ['Stationery','Stairs','Exercise','Walking','Sports']\n",
    "#     activity_list_wisdm = ['Sitting','Stairs','Jogging','Typing','Standing','Walking','Brushing','Eating','Drinking','Kicking',\n",
    "#                     'Playing Catch','Dribbling','Writing','Clapping','Folding Clothes']\n",
    "#     activity_list_dalia = ['Driving','Sitting','Stairs','Walking']\n",
    "#     print(data_windowed_10.schema)\n",
    "    schema = StructType(list(data_windowed_10.schema)[:2]+list(data_windowed_10.schema)[3:]+[StructField(\"magnitude\", ArrayType(DoubleType())),\n",
    "                                                                                            StructField(\"prediction\", StringType()),\n",
    "                                                                                            StructField(\"prediction_wisdm\", StringType()),\n",
    "                                                                                            StructField(\"prediction_dalia\", StringType()),\n",
    "                                                                                            StructField(\"mean\", DoubleType()),\n",
    "                                                                                            StructField(\"std\", DoubleType()),\n",
    "                                                                                            StructField(\"skew\", DoubleType()),\n",
    "                                                                                            StructField(\"kurtosis\", DoubleType())])\n",
    "#     print(schema)\n",
    "\n",
    "    \n",
    "#     def smooth_predictions(df):\n",
    "#         if df.shape[0]<3:\n",
    "#             return pd.DataFrame([],columns=columns)\n",
    "#         for name in ['prediction','prediction_wisdm','prediction_dalia']:\n",
    "#             y_activities = list(df[name])\n",
    "#             m_act = mode(y_activities)[0][0]\n",
    "#             df[name] = [m_act]*df.shape[0]\n",
    "#         return df\n",
    "\n",
    "    columns = [a.name for a in schema.fields]\n",
    "    print(columns)\n",
    "    @pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "    def interpolate_acl_magnitude(df):\n",
    "        df['magnitude_time'] = df['magnitude_time'].apply(lambda b:np.array([np.array(a) for a in b]).reshape(len(b),2))\n",
    "        df['magnitude_time'] = df['magnitude_time'].apply(lambda a:a[a[:,0].argsort()])\n",
    "        df['magnitude_time'] = df['magnitude_time'].apply(lambda a:a[:,1].reshape(a.shape[0],1))\n",
    "        \n",
    "        df['magnitude'] = df['magnitude_time'].apply(lambda a:interpolate_acl(a).reshape(1,window_size*new_Fs,1))\n",
    "        X = np.concatenate(list(df['magnitude']))\n",
    "        y_pred = model_wrapper.model.predict(X).argmax(axis=1)\n",
    "        df['prediction'] = list(y_pred.reshape(-1))\n",
    "        df['prediction'] = df['prediction'].apply(lambda a:final_activity_dict_reverse[a])\n",
    "\n",
    "        y_pred = model_wrapper_wisdm.model.predict(X).argmax(axis=1)\n",
    "        df['prediction_wisdm'] = list(y_pred.reshape(-1))\n",
    "        df['prediction_wisdm'] = df['prediction_wisdm'].apply(lambda a:activity_list_wisdm[a])\n",
    "        \n",
    "        y_pred = model_wrapper_dalia.model.predict(X).argmax(axis=1)\n",
    "        df['prediction_dalia'] = list(y_pred.reshape(-1))\n",
    "        df['prediction_dalia'] = df['prediction_dalia'].apply(lambda a:activity_list_dalia[a])\n",
    "        \n",
    "        df['magnitude'] = df['magnitude'].apply(lambda a:a.reshape(-1)) \n",
    "        df['mean'] = df['magnitude'].apply(lambda a:np.mean(a))\n",
    "        df['std'] = df['magnitude'].apply(lambda a:np.std(a))\n",
    "        df['skew'] = df['magnitude'].apply(lambda a:skew(a))\n",
    "        df['kurtosis'] = df['magnitude'].apply(lambda a:kurtosis(a))\n",
    "        df = df[columns]\n",
    "#         df = df.groupby(pd.Grouper(key='timestamp',freq=str(3*window_size)+'S'),as_index=False).apply(smooth_predictions)\n",
    "        return df\n",
    "\n",
    "    data_interpolated = data_windowed_10.groupBy(['user','version','day']).apply(interpolate_acl_magnitude)\n",
    "    schema = data_interpolated.schema\n",
    "#     data_interpolated.show(1,False)\n",
    "    stream_metadata = Metadata()\n",
    "    stream_metadata.set_name(stream_name+'.activity.all.three').set_description(\"Activity Computed\")\n",
    "    for field in schema.fields:\n",
    "        stream_metadata.add_dataDescriptor(\n",
    "            DataDescriptor().set_name(str(field.name)).set_type(str(field.dataType))\n",
    "        )\n",
    "    stream_metadata.add_module(\n",
    "        ModuleMetadata().set_name(\"activity datastream\") \\\n",
    "        .set_attribute(\"url\", \"https://md2k.org\").set_author(\n",
    "            \"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "    stream_metadata.is_valid()\n",
    "    data_interpolated.printSchema()\n",
    "    ds = DataStream(data=data_interpolated,metadata=stream_metadata)\n",
    "    return ds\n",
    "# CC.save_stream(ds,overwrite=True)\n",
    "\n",
    "# stream_name = 'org.md2k.feature.motionsensehrv.decoded.rightwrist.all'\n",
    "stream_name = 'accelerometer--org.md2k.motionsense--motion_sense--right_wrist'\n",
    "data = CC.get_stream(stream_name)\n",
    "data.show(5,False)\n",
    "data_activity = compute_magnitude_and_activity(data,stream_name=stream_name)\n",
    "CC.save_stream(data_activity,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CC.get_stream(stream_name+'.activity.all.three')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|prediction|count  |\n",
      "+----------+-------+\n",
      "|Stairs    |9494   |\n",
      "|Walking   |26275  |\n",
      "|Stationery|1190228|\n",
      "|Sports    |89905  |\n",
      "|Exercise  |633    |\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy('prediction').count().show(5,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampling mperf data to 20Hz and computes the magnitude and applies activity recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import tensorflow \n",
    "\n",
    "def interpolate_acl(a,window_size=20,fs_now=25,fs_new=20):\n",
    "    x_now = np.linspace(0,window_size,a.shape[0])\n",
    "    f = interp1d(x_now,a,axis=0,fill_value='extrapolate')\n",
    "    x_new = np.linspace(0,window_size,window_size*fs_new)\n",
    "    return f(x_new)\n",
    "\n",
    "class ModelWrapperPickable:\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def __getstate__(self):\n",
    "        model_str = ''\n",
    "        with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:\n",
    "            tensorflow.keras.models.save_model(self.model, fd.name, overwrite=True)\n",
    "            model_str = fd.read()\n",
    "        d = { 'model_str': model_str }\n",
    "        return d\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:\n",
    "            fd.write(state['model_str'])\n",
    "            fd.flush()\n",
    "            self.model = tensorflow.keras.models.load_model(fd.name)\n",
    "\n",
    "\n",
    "def isDatapointsWithinRange(red,infrared,green,window_size=20):\n",
    "        red = np.asarray(red, dtype=np.float32)\n",
    "        infrared = np.asarray(infrared, dtype=np.float32)\n",
    "        green = np.asarray(green, dtype=np.float32)\n",
    "        a =  len(np.where((red >= 20000)& (red<=200000))[0]) < .33*window_size*25\n",
    "        b = len(np.where((infrared >= 80000)& (infrared<=230000))[0]) < .33*window_size*25\n",
    "        c = len(np.where((green >= 500)& (green<=25000))[0]) < .33*window_size*25\n",
    "        if a and b and c:\n",
    "            return False\n",
    "        return True            \n",
    "\n",
    "            \n",
    "def compute_quality(red,infrared,green):\n",
    "        \"\"\"\n",
    "        :param window: a window containing list of DataPoints\n",
    "        :return: an integer reptresenting the status of the window 0= attached, 1 = not attached\n",
    "        \"\"\"\n",
    "        if len(red)==0:\n",
    "            return 'Not Worn' #not attached\n",
    "        if not isDatapointsWithinRange(red,infrared,green):\n",
    "            return 'Not Worn'\n",
    "        red_mean = np.mean(red)\n",
    "        ir_mean = np.mean(infrared)\n",
    "        green_mean = np.mean(green)\n",
    "        if red_mean < 5000 and ir_mean < 5000:\n",
    "            return 'Not Worn'\n",
    "        if not (red_mean>green_mean and ir_mean>red_mean):\n",
    "            return 'Not Worn'\n",
    "        diff = 30000\n",
    "        if red_mean<130000:\n",
    "            diff = 10000\n",
    "        if red_mean - green_mean <= diff:\n",
    "            return 'Not Worn'\n",
    "        if ir_mean - red_mean <= diff:\n",
    "            return 'Not Worn'\n",
    "        return 'Worn'            \n",
    "            \n",
    "\n",
    "def compute_magnitude_and_activity(data,\n",
    "                                   Fs = 25,\n",
    "                                   window_size = 20,\n",
    "                                   stream_name = 'org.md2k.feature.motionsensehrv.decoded.rightwrist.all',\n",
    "                                   new_Fs = 20,\n",
    "                                   acceptable_percentage = .8,\n",
    "                                   filename1 = './models/activity_estimator_both_study_magnitude_final_5_labels.hdf5',\n",
    "                                   filename2 = './models/activity_estimator_wisdm_magnitude_final_5_labels.hdf5',\n",
    "                                   filename3 = './models/activity_estimator_dalia_magnitude_final_5_labels.hdf5'):\n",
    "            \n",
    "    model = load_model(filename1)\n",
    "\n",
    "    model_wrapper= ModelWrapperPickable(model)\n",
    "\n",
    "\n",
    "    model_wisdm = load_model(filename2)\n",
    "\n",
    "    model_wrapper_wisdm= ModelWrapperPickable(model_wisdm)\n",
    "    \n",
    "    model_dalia = load_model(filename3)\n",
    "\n",
    "    model_wrapper_dalia = ModelWrapperPickable(model_dalia)\n",
    "\n",
    "\n",
    "    data = data.select('localtime','timestamp','aclx','acly','aclz','user','version','red','infrared','green')\n",
    "\n",
    "    data = data.withColumn('magnitude',F.sqrt(F.pow(F.col('aclx'),2)+F.pow(F.col('acly'),2)+F.pow(F.col('aclz'),2))).drop('aclx','acly','aclz')\n",
    "\n",
    "    data = data.withColumn('time',F.col('timestamp').cast('double'))\n",
    "\n",
    "    data = data.withColumn('magnitude_time',F.array('time','magnitude')).drop('time','magnitude')\n",
    "\n",
    "    groupbycols = ['user','version',\n",
    "                   F.window('timestamp',windowDuration=str(window_size)+' seconds', startTime='0 seconds')]\n",
    "    data_windowed_10 = data.groupBy(groupbycols).agg(F.collect_list('magnitude_time'),\n",
    "                                                     F.collect_list('localtime'),\n",
    "                                                    F.collect_list('red'),\n",
    "                                                    F.collect_list('infrared'),\n",
    "                                                    F.collect_list('green'))\n",
    "\n",
    "    data_windowed_10 = data_windowed_10.withColumnRenamed('collect_list(magnitude_time)','magnitude_time')\n",
    "    data_windowed_10 = data_windowed_10.withColumnRenamed('collect_list(localtime)','localtime')\n",
    "    \n",
    "    data_windowed_10 = data_windowed_10.withColumnRenamed('collect_list(red)','red')\n",
    "    data_windowed_10 = data_windowed_10.withColumnRenamed('collect_list(infrared)','infrared')\n",
    "    data_windowed_10 = data_windowed_10.withColumnRenamed('collect_list(green)','green')\n",
    "\n",
    "    qfunction = F.udf(compute_quality,StringType())\n",
    "    data_windowed_10 = data_windowed_10.withColumn('quality',qfunction(data_windowed_10['red'],data_windowed_10['infrared'],data_windowed_10['green']))\n",
    "\n",
    "    data_windowed_10 = data_windowed_10.drop('red','infrared','green')\n",
    "    \n",
    "    data_windowed_10 = data_windowed_10.filter(F.col('quality')=='Worn').drop('quality')\n",
    "\n",
    "    \n",
    "    data_windowed_10 = data_windowed_10.withColumn('localtime',F.col('localtime').getItem(0))\n",
    "\n",
    "    data_windowed_10 = data_windowed_10.withColumn('length',F.size('magnitude_time'))\n",
    "\n",
    "    data_windowed_10 = data_windowed_10.filter(F.col('length')>=acceptable_percentage*window_size*Fs).drop('length')\n",
    "\n",
    "    data_windowed_10 = data_windowed_10.withColumn('timestamp',F.col('window').start).withColumn('start',F.col('window').start).withColumn('end',F.col('window').end).drop('window')\n",
    "\n",
    "    data_windowed_10  = data_windowed_10.withColumn('day',F.date_format('localtime',\"yyyyMMdd\"))\n",
    "\n",
    "    final_activity_list = ['Stationery','Stairs','Exercise','Walking','Sports']\n",
    "    final_activity_dict = {a:i for i,a in enumerate(final_activity_list)}\n",
    "    final_activity_dict_reverse = {i:a for i,a in enumerate(final_activity_list)}\n",
    "    activity_list_wisdm = ['Stationery','Stairs','Exercise','Walking','Sports']\n",
    "    activity_list_dalia = ['Stationery','Stairs','Exercise','Walking','Sports']\n",
    "#     activity_list_wisdm = ['Sitting','Stairs','Jogging','Typing','Standing','Walking','Brushing','Eating','Drinking','Kicking',\n",
    "#                     'Playing Catch','Dribbling','Writing','Clapping','Folding Clothes']\n",
    "#     activity_list_dalia = ['Driving','Sitting','Stairs','Walking']\n",
    "#     print(data_windowed_10.schema)\n",
    "    schema = StructType(list(data_windowed_10.schema)[:2]+list(data_windowed_10.schema)[3:]+[StructField(\"magnitude\", ArrayType(DoubleType())),\n",
    "                                                                                            StructField(\"prediction\", StringType()),\n",
    "                                                                                            StructField(\"prediction_wisdm\", StringType()),\n",
    "                                                                                            StructField(\"prediction_dalia\", StringType()),\n",
    "                                                                                            StructField(\"mean\", DoubleType()),\n",
    "                                                                                            StructField(\"std\", DoubleType()),\n",
    "                                                                                            StructField(\"skew\", DoubleType()),\n",
    "                                                                                            StructField(\"kurtosis\", DoubleType())])\n",
    "#     print(schema)\n",
    "\n",
    "    \n",
    "    def smooth_predictions(df):\n",
    "        if df.shape[0]<3:\n",
    "            return pd.DataFrame([],columns=columns)\n",
    "        for name in ['prediction','prediction_wisdm','prediction_dalia']:\n",
    "            y_activities = list(df[name])\n",
    "            m_act = mode(y_activities)[0][0]\n",
    "            df[name] = [m_act]*df.shape[0]\n",
    "        return df\n",
    "\n",
    "    columns = [a.name for a in schema.fields]\n",
    "    @pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "    def interpolate_acl_magnitude(df):\n",
    "        df['magnitude_time'] = df['magnitude_time'].apply(lambda b:np.array([np.array(a) for a in b]).reshape(len(b),2))\n",
    "        df['magnitude_time'] = df['magnitude_time'].apply(lambda a:a[a[:,0].argsort()])\n",
    "        df['magnitude_time'] = df['magnitude_time'].apply(lambda a:a[:,1].reshape(a.shape[0],1))\n",
    "        \n",
    "        df['magnitude'] = df['magnitude_time'].apply(lambda a:interpolate_acl(a).reshape(1,window_size*new_Fs,1))\n",
    "        X = np.concatenate(list(df['magnitude']))\n",
    "        y_pred = model_wrapper.model.predict(X).argmax(axis=1)\n",
    "        df['prediction'] = list(y_pred.reshape(-1))\n",
    "        df['prediction'] = df['prediction'].apply(lambda a:final_activity_dict_reverse[a])\n",
    "\n",
    "        y_pred = model_wrapper_wisdm.model.predict(X).argmax(axis=1)\n",
    "        df['prediction_wisdm'] = list(y_pred.reshape(-1))\n",
    "        df['prediction_wisdm'] = df['prediction_wisdm'].apply(lambda a:activity_list_wisdm[a])\n",
    "        \n",
    "        y_pred = model_wrapper_dalia.model.predict(X).argmax(axis=1)\n",
    "        df['prediction_dalia'] = list(y_pred.reshape(-1))\n",
    "        df['prediction_dalia'] = df['prediction_dalia'].apply(lambda a:activity_list_dalia[a])\n",
    "        \n",
    "        df['magnitude'] = df['magnitude'].apply(lambda a:a.reshape(-1)) \n",
    "        df['mean'] = df['magnitude'].apply(lambda a:np.mean(a))\n",
    "        df['std'] = df['magnitude'].apply(lambda a:np.std(a))\n",
    "        df['skew'] = df['magnitude'].apply(lambda a:skew(a))\n",
    "        df['kurtosis'] = df['magnitude'].apply(lambda a:kurtosis(a))\n",
    "        df = df[columns]\n",
    "#         df = df.groupby(pd.Grouper(key='timestamp',freq=str(3*window_size)+'S'),as_index=False).apply(smooth_predictions)\n",
    "        return df\n",
    "\n",
    "    data_interpolated = data_windowed_10.groupBy(['user','version','day']).apply(interpolate_acl_magnitude)\n",
    "    schema = data_interpolated.schema\n",
    "    stream_metadata = Metadata()\n",
    "    stream_metadata.set_name(stream_name+'.activity.all.three').set_description(\"Activity Computed\")\n",
    "    for field in schema.fields:\n",
    "        stream_metadata.add_dataDescriptor(\n",
    "            DataDescriptor().set_name(str(field.name)).set_type(str(field.dataType))\n",
    "        )\n",
    "    stream_metadata.add_module(\n",
    "        ModuleMetadata().set_name(\"activity datastream\") \\\n",
    "        .set_attribute(\"url\", \"https://md2k.org\").set_author(\n",
    "            \"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "    stream_metadata.is_valid()\n",
    "    data_interpolated.printSchema()\n",
    "    ds = DataStream(data=data_interpolated,metadata=stream_metadata)\n",
    "    return ds\n",
    "# CC.save_stream(ds,overwrite=True)\n",
    "\n",
    "stream_name = 'org.md2k.feature.motionsensehrv.decoded.rightwrist.all'\n",
    "data = CC.get_stream(stream_name)\n",
    "data.show(5,False)\n",
    "data_activity = compute_magnitude_and_activity(data,stream_name=stream_name)\n",
    "CC.save_stream(data_activity,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CC.get_stream('org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity.all.three')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select('prediction').groupBy('prediction').count().show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = CC.get_stream('org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity.all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupBy('prediction_dalia').count().show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_data = CC.get_stream('org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity.all')\n",
    "\n",
    "count_data = right_data.select('user','prediction','day').groupBy(['user','prediction','day']).count()\n",
    "df = count_data.toPandas()\n",
    "import pickle\n",
    "pickle.dump(df,open('./data/right_wrist_count.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_mean = df.groupby(['prediction','user'],as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_mean.groupby('prediction').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_data = CC.get_stream('org.md2k.feature.motionsensehrv.decoded.rightwrist.all.activity')\n",
    "\n",
    "count_data = right_data.select('user','prediction_wisdm','day').groupBy(['user','prediction_wisdm','day']).count()\n",
    "df = count_data.toPandas()\n",
    "import pickle\n",
    "pickle.dump(df,open('./data/right_wrist_count_wisdm.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "df = pickle.load(open('./data/right_wrist_count.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './data/20/walking/testing/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for f in os.listdir(directory):\n",
    "    data = pickle.load(open(directory+f,'rb'))\n",
    "    if data.shape[0]//3>100:\n",
    "        count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count'] = df['count'].apply(lambda a:(a*10)/3600)\n",
    "df['prediction'][df['prediction'].isin(['Sitting','Eating'])] = ['Sitting']*df[df['prediction'].isin(['Sitting','Eating'])].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_walking = df[df['prediction']=='Sitting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(df_walking[['user','count']].groupby('user').quantile(.5)['count'],20)\n",
    "plt.title('Maximum walking hours for a single day')\n",
    "plt.xlabel('Hours')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./images/Maximumwalk.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_walking.groupby('user').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_mean = df.groupby(['user','prediction'],as_index=False).mean()\n",
    "plt.rcParams.update({'font.size':20})\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.boxplot(x='prediction',y='count',data=df_user_mean)\n",
    "plt.xticks(rotation='60')\n",
    "plt.ylabel('Hours')\n",
    "plt.savefig('./images/user_mean_per_day.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(df_user_mean['count'][df_user_mean['prediction'].isin(['Walking','Stairs','Sports','Exercise'])],300,density=True)\n",
    "plt.xlim([0,2])\n",
    "plt.title('Moving Hours per day distribution')\n",
    "plt.xlabel('Hours')\n",
    "plt.savefig('./images/moving_hours_per_day.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_activity_list = ['Brushing','Cycling','Sports','Eating','Driving',\n",
    "#                        'Exercise','Sitting','Stairs','Standing','Walking']\n",
    "def percentage(df):\n",
    "    activities = np.unique(df['prediction'])\n",
    "    result  = []\n",
    "    for a in activities:\n",
    "        result.append(100*df['count'][df['prediction']==a].values[0]/df['count'].sum())\n",
    "    users = [df.user.values[0]]*len(result)\n",
    "    return pd.DataFrame({'activities':activities,'user':users,'percentage':result})\n",
    "\n",
    "df_user_percentage = df_user_mean.groupby('user',as_index=False).apply(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size':20})\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.boxplot(x='activities',y='percentage',data=df_user_percentage)\n",
    "plt.xticks(rotation=60)\n",
    "plt.savefig('./images/user_percentage_per_day.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_name = 'org.md2k.feature.motionsensehrv.decoded.leftwrist.all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CC.get_stream(stream_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select('user').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_activity.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "61692/(25*3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_activity.show(4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('hdfs://dantooine10dot.memphis.edu/user/mullah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('./data/right_wrist/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "High Performance CC3.3",
   "language": "python",
   "name": "cc33_high_performance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
