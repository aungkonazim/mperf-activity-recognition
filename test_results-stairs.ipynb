{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "continuing-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_testing_data(directory,min_length,window_size):\n",
    "    X = []\n",
    "    y = []\n",
    "    n = 60//window_size\n",
    "    for f in os.listdir(directory):\n",
    "        if f[0]=='.':\n",
    "            continue\n",
    "        data = pickle.load(open(directory+f,'rb'))\n",
    "        if data.shape[0]//n<min_length:\n",
    "            continue\n",
    "        X.append(np.concatenate(list(data['data'])))\n",
    "        y.extend([f]*data.shape[0])\n",
    "    return np.concatenate(X),np.array(y)\n",
    "\n",
    "window_size = 20\n",
    "activity = 'std25'\n",
    "n_user  = 315\n",
    "min_length = 100\n",
    "data_directory = './data/'+str(window_size)+'/'+activity+'/testing/'\n",
    "model_directory = './models/'+str(window_size)+'/'+activity+'/'+str(n_user)+'/'\n",
    "train_lengths = os.listdir(model_directory)\n",
    "# X,y = get_testing_data(data_directory,min_length,window_size)\n",
    "save_directory = './predictions/'+str(window_size)+'/'+activity+'/'+str(n_user)+'/'\n",
    "result_directory = './results/'\n",
    "if not os.path.isdir(save_directory):\n",
    "    os.makedirs(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "incorporated-scenario",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[2], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mediterranean-puzzle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 done\n",
      "10 done\n",
      "60 done\n",
      "20 done\n",
      "50 done\n",
      "30 done\n",
      "120 done\n",
      "90 done\n",
      "150 done\n",
      "180 done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def get_dictfilename(a):\n",
    "    a = a.replace('trainedmodel','userdict').replace('hdf5','p')\n",
    "    return a\n",
    "\n",
    "def get_predictions(df):\n",
    "    indexes = np.array(list(df['index']))\n",
    "    y_pred = model.predict(X[indexes])\n",
    "    df['y_prob'] = list(y_pred)\n",
    "    df['y_pred'] = y_pred.argmax(axis=1)\n",
    "    return df\n",
    "    \n",
    "\n",
    "for f in list(os.listdir(model_directory)):\n",
    "    model_files = [model_directory+f+'/'+a for a in os.listdir(model_directory+f) if a[-1]=='5']\n",
    "    dict_files = [get_dictfilename(a) for a in model_files]\n",
    "    pairs = list(zip(model_files,dict_files))\n",
    "    predictions_all = []\n",
    "    for i,a in enumerate(pairs):\n",
    "        m_name,d_name = a\n",
    "        user_dict = pickle.load(open(d_name,'rb'))\n",
    "        y_final = np.array([user_dict[a] for a in y])\n",
    "        index_df = pd.DataFrame({'user':y,'y':y_final,'index':np.arange(len(y))})\n",
    "        model = tf.keras.models.load_model(m_name)\n",
    "        predictions = index_df.groupby('user',as_index=False).apply(get_predictions)\n",
    "        predictions['iteration'] = i\n",
    "        predictions_all.append(predictions)\n",
    "    predictions_all = pd.concat(predictions_all)\n",
    "    pickle.dump(predictions_all,open(save_directory+f,'wb'))\n",
    "    print(f,'done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "informal-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import mode\n",
    "\n",
    "def get_results(df):\n",
    "    df['y_prob'] = df['y_prob'].apply(lambda a:a.reshape(1,-1))\n",
    "    rows = []\n",
    "    rows.append([0,accuracy_score(df['y'],df['y_pred']),accuracy_score(df['y'],df['y_pred']),np.int64(f),df['user'].values[0],df['iteration'].values[0]])\n",
    "    for t in test_lengths:\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        y_pred_maxmean = []\n",
    "        for j in range(n_iter):\n",
    "            n = t*3\n",
    "            if n>df.shape[0]:\n",
    "                continue\n",
    "            temp_df = df.sample(n,replace=False)\n",
    "            y_true.append(temp_df['y'].values[0])\n",
    "            y_pred.append(mode(temp_df['y_pred'])[0][0])\n",
    "            y_pred_maxmean.append(np.concatenate(list(temp_df['y_prob'])).mean(axis=0).argmax())\n",
    "        rows.append([t,accuracy_score(y_true,y_pred),accuracy_score(y_true,y_pred_maxmean),np.int64(f),df['user'].values[0],df['iteration'].values[0]])\n",
    "    return pd.DataFrame(rows,columns=['test_length','majority_score',\n",
    "                                      'maxmean_score','train_length',\n",
    "                                      'user','iteration'])\n",
    "\n",
    "\n",
    "import sys\n",
    "from joblib import Parallel,delayed\n",
    "if activity=='stationery':\n",
    "    test_lengths = list(np.arange(1,10,1))+list(np.arange(10,120,10))+list(np.arange(120,240,20))+list(np.arange(240,480,40))\n",
    "else:\n",
    "    test_lengths = list(np.arange(1,10,1))+list(np.arange(10,60,5))\n",
    "n_iter = 100\n",
    "base_window_size = 20\n",
    "final_results = []\n",
    "train_lengths = []\n",
    "\n",
    "# if activity+'.p' in os.listdir(result_directory):\n",
    "#     df = pickle.load(open(result_directory+activity+'.p','rb'))\n",
    "#     final_results.append(df)\n",
    "#     train_lengths = [str(a) for a in df['train_length'].unique()]\n",
    "    \n",
    "for f in os.listdir(save_directory):\n",
    "    if f in train_lengths:\n",
    "        continue\n",
    "    print(f)\n",
    "    dd = pickle.load(open(save_directory+f,'rb'))\n",
    "    all_dfs = list(dd.groupby(['user','iteration'],as_index=False))\n",
    "    all_results = Parallel(n_jobs=30,verbose=2)(delayed(get_results)(all_dfs[k][1]) for k in range(len(all_dfs)))\n",
    "    results = pd.concat(all_results)\n",
    "    final_results.append(results)\n",
    "    pickle.dump(pd.concat(final_results),open(result_directory+activity+'.p','wb'))\n",
    "    print(f,'done')\n",
    "\n",
    "results = pickle.load(open(result_directory+activity+'.p','rb'))\n",
    "\n",
    "final_results = results.groupby(['test_length','iteration','train_length'],as_index=False).mean().groupby(['test_length','train_length'],as_index=False).mean()\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({'font.size':40})\n",
    "plt.figure(figsize=(30,20))\n",
    "sns.lineplot(x='test_length',y='majority_score',hue='train_length',data=final_results)\n",
    "plt.ylim([0,1])\n",
    "plt.show()\n",
    "plt.rcParams.update({'font.size':40})\n",
    "plt.figure(figsize=(30,20))\n",
    "sns.lineplot(x='test_length',y='maxmean_score',hue='train_length',data=final_results)\n",
    "plt.ylim([0,1])\n",
    "plt.show()\n",
    "\n",
    "def save_data_final():\n",
    "    final_result_directory = './final_results/'\n",
    "    if not os.path.isdir(final_result_directory):\n",
    "        os.makedirs(final_result_directory)\n",
    "    activity1 = activity\n",
    "    if activity=='std':\n",
    "        activity1 += '20'\n",
    "    maxmean = pd.pivot_table(final_results,columns='train_length',index='test_length',values='maxmean_score',aggfunc='mean')\n",
    "    maxmean.to_csv(final_result_directory+activity1+'_maxmean.csv')\n",
    "    majority = pd.pivot_table(final_results,columns='train_length',index='test_length',values='majority_score',aggfunc='mean')\n",
    "    majority.to_csv(final_result_directory+activity1+'_majority.csv')\n",
    "\n",
    "save_data_final()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
