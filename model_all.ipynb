{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cerebralcortex/kessel_jupyter_virtualenv/tensorflow/lib/python3.7/site-packages/pandas-1.2.3-py3.7-linux-x86_64.egg/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "seed = 4\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Conv1D,BatchNormalization,Dropout,Input,MaxPooling1D,Flatten,Dense,Input,Activation,GRU\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import Parallel,delayed\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cerebralcortex/kessel_jupyter_virtualenv/tensorflow/lib/python3.7/site-packages/pandas-1.2.3-py3.7-linux-x86_64.egg/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "def get_participants_df(directory,window_size,min_length):\n",
    "    df = []\n",
    "    n = 60//window_size\n",
    "    for f in os.listdir(directory):\n",
    "        data = pickle.load(open(directory+f,'rb'))\n",
    "        df.append([f,data.shape[0]//n])\n",
    "    df = pd.DataFrame(df,columns=['user','total_test_length'])\n",
    "    return df[df.total_test_length>=min_length]\n",
    "\n",
    "def get_training_data(directory,\n",
    "                      train_length,\n",
    "                      n_user,\n",
    "                      participant_df,\n",
    "                      window_size):\n",
    "    n = 60//window_size\n",
    "    users = participant_df['user'].values[:n_user]\n",
    "    X = []\n",
    "    y = []\n",
    "    for f in users:\n",
    "        df = pickle.load(open(directory+f,'rb'))\n",
    "        i = np.random.randint(0,df.shape[0]-n*train_length)\n",
    "        df = df[i:i+n*train_length]\n",
    "        X.append(np.concatenate(list(df['data'])))\n",
    "        y.extend([f]*df.shape[0])\n",
    "    y_dict = {a:i for i,a in enumerate(np.unique(y))}\n",
    "    y  = [y_dict[a] for a in y]\n",
    "    return np.concatenate(X),np.array(y),y_dict\n",
    "\n",
    "def get_trained_model(X_train,y_train,n_timesteps,n_channels,window_size,filepath):\n",
    "    n_classes = len(np.unique(y_train))\n",
    "    model =  get_model(input_shape=(n_timesteps,n_channels),n_classes=n_classes)\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='min',save_weights_only=False)\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=0,patience=40)\n",
    "    lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',patience=5,verbose=0,factor=0.5)\n",
    "    callbacks_list = [es,checkpoint]\n",
    "    train_x,val_x,train_y,val_y = train_test_split(X_train,y_train,test_size=.1,stratify=y_train)\n",
    "    history = model.fit(train_x,train_y,validation_data=(val_x,val_y), epochs=200, batch_size=300,verbose=0,callbacks=callbacks_list,shuffle=True)\n",
    "    model.load_weights(filepath)\n",
    "    print(accuracy_score(val_y,model.predict(val_x).argmax(axis=1)),end=',')\n",
    "    return model\n",
    "\n",
    "def get_model(input_shape=(500,3),n_classes=1):\n",
    "    model =  Sequential()\n",
    "    model.add(Conv1D(128,2,input_shape=input_shape,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Conv1D(128,2,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(GRU(128,return_sequences=True,activation='tanh'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(400,name='feature',activation='relu'))\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Dense(n_classes,activation='softmax'))\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),optimizer='rmsprop')\n",
    "    return model\n",
    "\n",
    "\n",
    "window_size = 20\n",
    "activity = 'walking'\n",
    "data_directory = './data/'+str(window_size)+'/'+activity+'/'\n",
    "model_directory = './models/'+str(window_size)+'/'+activity+'/'\n",
    "min_test_total_length  = 100\n",
    "fs = 25\n",
    "n_timesteps,n_channels = fs*window_size,3 \n",
    "if not os.path.isdir(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "participant_df = get_participants_df(data_directory+'testing/',window_size,min_test_total_length)\n",
    "n_users = list(np.arange(50,participant_df.shape[0],50))+[participant_df.shape[0]]\n",
    "train_lengths = np.arange(10,180,10)\n",
    "n_iters = np.arange(20)\n",
    "\n",
    "for n_user in n_users[::-1]:\n",
    "    if not os.path.isdir(model_directory+str(n_user)):\n",
    "        os.makedirs(model_directory+str(n_user))\n",
    "    print('--'*30)\n",
    "    print('Starting for no. of training users = ',n_user)\n",
    "    for train_length in train_lengths:\n",
    "        print('Training length minutes = ',train_length)\n",
    "        if not os.path.isdir(model_directory+str(n_user)+'/'+str(train_length)):\n",
    "            os.makedirs(model_directory+str(n_user)+'/'+str(train_length))\n",
    "        for n_iter in n_iters:\n",
    "            X_train,y_train,user_dict = get_training_data(directory = data_directory+'training/',\n",
    "                                                          train_length=train_length,\n",
    "                                                          n_user=n_user,\n",
    "                                                          participant_df=participant_df,\n",
    "                                                          window_size=window_size) \n",
    "            pickle.dump(user_dict,open(model_directory+str(n_user)+'/'+str(train_length)+'/user_dict_seed_'+str(seed)+'_iteration_'+str(n_iter)+'.p','wb'))\n",
    "            model = get_model(input_shape=(n_timesteps,n_channels),n_classes=len(np.unique(y_train)))\n",
    "            model_filepath = model_directory+str(n_user)+'/'+str(train_length)+'/trained_model_seed_'+str(seed)+'_iteration_'+str(n_iter)+'.hdf5'\n",
    "            model = get_trained_model(X_train,y_train,n_timesteps,n_channels,window_size,model_filepath)\n",
    "            print('iteration = ',n_iter)\n",
    "        print(train_length, '--Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
